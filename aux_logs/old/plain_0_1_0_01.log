/home/soyoung/latent_ode0/train_aux.py
train_aux.py --niters 5 -n 8000 -l 20 --latent-ode --z0-encoder rnn --dataset physionet --rec-dims 40 --rec-layers 3 --gen-layers 3 --units 50 --gru-units 50 --quantization 0.016 --classif --alpha 0.01
### Auxiliary Network : step size 0.1###
Iter: 1 | Train loss (one batch): 1.2540957927703857
Iter: 2 | Train loss (one batch): 1.241926908493042
Iter: 3 | Train loss (one batch): 1.235296607017517
Iter: 4 | Train loss (one batch): 1.2067413330078125
Iter: 5 | Train loss (one batch): 1.1700078248977661
Iter: 6 | Train loss (one batch): 1.1568660736083984
Iter: 7 | Train loss (one batch): 1.129639983177185
Iter: 8 | Train loss (one batch): 1.1142876148223877
Iter: 9 | Train loss (one batch): 1.098075270652771
Iter: 10 | Train loss (one batch): 1.0762860774993896
Iter: 11 | Train loss (one batch): 1.059438705444336
Iter: 12 | Train loss (one batch): 1.0480552911758423
Iter: 13 | Train loss (one batch): 1.0260915756225586
Iter: 14 | Train loss (one batch): 0.9888149499893188
Iter: 15 | Train loss (one batch): 0.9818500280380249
Iter: 16 | Train loss (one batch): 0.9290904402732849
Iter: 17 | Train loss (one batch): 0.8956040740013123
Iter: 18 | Train loss (one batch): 0.8789916038513184
Iter: 19 | Train loss (one batch): 0.8622826933860779
Iter: 20 | Train loss (one batch): 0.8395985960960388
Iter: 21 | Train loss (one batch): 0.8058019876480103
Iter: 22 | Train loss (one batch): 0.8323944211006165
Iter: 23 | Train loss (one batch): 0.7858213782310486
Iter: 24 | Train loss (one batch): 0.779075026512146
Iter: 25 | Train loss (one batch): 0.7493978142738342
Iter: 26 | Train loss (one batch): 0.7276544570922852
Iter: 27 | Train loss (one batch): 0.7086764574050903
Iter: 28 | Train loss (one batch): 0.6774033308029175
Iter: 29 | Train loss (one batch): 0.649678111076355
Iter: 30 | Train loss (one batch): 0.6402308940887451
Iter: 31 | Train loss (one batch): 0.5922071933746338
Iter: 32 | Train loss (one batch): 0.5372490286827087
Iter: 33 | Train loss (one batch): 0.5208478569984436
Iter: 34 | Train loss (one batch): 0.5052163004875183
Iter: 35 | Train loss (one batch): 0.48762446641921997
Iter: 36 | Train loss (one batch): 0.45530882477760315
Iter: 37 | Train loss (one batch): 0.4444177448749542
Iter: 38 | Train loss (one batch): 0.4313448369503021
Iter: 39 | Train loss (one batch): 0.4562509059906006
Iter: 40 | Train loss (one batch): 0.4353731870651245
Iter: 41 | Train loss (one batch): 0.4592745900154114
Iter: 42 | Train loss (one batch): 0.4445599615573883
Iter: 43 | Train loss (one batch): 0.4120490550994873
Iter: 44 | Train loss (one batch): 0.4477582275867462
Iter: 45 | Train loss (one batch): 0.42231929302215576
Iter: 46 | Train loss (one batch): 0.4167598485946655
Iter: 47 | Train loss (one batch): 0.3730538785457611
Iter: 48 | Train loss (one batch): 0.4247971773147583
Iter: 49 | Train loss (one batch): 0.3745103180408478
Iter: 50 | Train loss (one batch): 0.3808787167072296
Iter: 51 | Train loss (one batch): 0.39928847551345825
Iter: 52 | Train loss (one batch): 0.3743302524089813
Iter: 53 | Train loss (one batch): 0.38837891817092896
Iter: 54 | Train loss (one batch): 0.38367795944213867
Iter: 55 | Train loss (one batch): 0.34510114789009094
Iter: 56 | Train loss (one batch): 0.3444994390010834
Iter: 57 | Train loss (one batch): 0.351529061794281
Iter: 58 | Train loss (one batch): 0.342397004365921
Iter: 59 | Train loss (one batch): 0.36672964692115784
Iter: 60 | Train loss (one batch): 0.37297677993774414
Iter: 61 | Train loss (one batch): 0.32394707202911377
Iter: 62 | Train loss (one batch): 0.3476179540157318
Iter: 63 | Train loss (one batch): 0.32124021649360657
Iter: 64 | Train loss (one batch): 0.33742213249206543
Iter: 65 | Train loss (one batch): 0.33451130986213684
Iter: 66 | Train loss (one batch): 0.3741993010044098
Iter: 67 | Train loss (one batch): 0.3238928020000458
Iter: 68 | Train loss (one batch): 0.33373525738716125
Iter: 69 | Train loss (one batch): 0.3019881844520569
Iter: 70 | Train loss (one batch): 0.34051287174224854
Iter: 71 | Train loss (one batch): 0.3214608430862427
Iter: 72 | Train loss (one batch): 0.3105442523956299
Iter: 73 | Train loss (one batch): 0.3176118731498718
Iter: 74 | Train loss (one batch): 0.3332829177379608
Iter: 75 | Train loss (one batch): 0.331172376871109
Iter: 76 | Train loss (one batch): 0.32539597153663635
Iter: 77 | Train loss (one batch): 0.32284975051879883
Iter: 78 | Train loss (one batch): 0.3199414312839508
Iter: 79 | Train loss (one batch): 0.31466200947761536
Iter: 80 | Train loss (one batch): 0.28202173113822937
Iter: 81 | Train loss (one batch): 0.3011412024497986
Iter: 82 | Train loss (one batch): 0.28381070494651794
Iter: 83 | Train loss (one batch): 0.30093055963516235
Iter: 84 | Train loss (one batch): 0.29912787675857544
Iter: 85 | Train loss (one batch): 0.3195077180862427
Iter: 86 | Train loss (one batch): 0.31993186473846436
Iter: 87 | Train loss (one batch): 0.3105899691581726
Iter: 88 | Train loss (one batch): 0.29722821712493896
Iter: 89 | Train loss (one batch): 0.309796541929245
Iter: 90 | Train loss (one batch): 0.2779715061187744
Iter: 91 | Train loss (one batch): 0.2762754261493683
Iter: 92 | Train loss (one batch): 0.295355886220932
Iter: 93 | Train loss (one batch): 0.2963191270828247
Iter: 94 | Train loss (one batch): 0.2894802987575531
Iter: 95 | Train loss (one batch): 0.2830863296985626
Iter: 96 | Train loss (one batch): 0.2582889497280121
Iter: 97 | Train loss (one batch): 0.28316056728363037
Iter: 98 | Train loss (one batch): 0.269232839345932
Iter: 99 | Train loss (one batch): 0.2888880670070648
Iter: 100 | Train loss (one batch): 0.28610220551490784
Iter: 101 | Train loss (one batch): 0.2663678824901581
Iter: 102 | Train loss (one batch): 0.25220999121665955
Iter: 103 | Train loss (one batch): 0.2618050277233124
Iter: 104 | Train loss (one batch): 0.2575870454311371
Iter: 105 | Train loss (one batch): 0.2564520537853241
Iter: 106 | Train loss (one batch): 0.2771395146846771
Iter: 107 | Train loss (one batch): 0.29486680030822754
Iter: 108 | Train loss (one batch): 0.25315114855766296
Iter: 109 | Train loss (one batch): 0.2523282766342163
Iter: 110 | Train loss (one batch): 0.24096758663654327
Iter: 111 | Train loss (one batch): 0.2544519901275635
Iter: 112 | Train loss (one batch): 0.25046685338020325
Iter: 113 | Train loss (one batch): 0.25760018825531006
Iter: 114 | Train loss (one batch): 0.2510516345500946
Iter: 115 | Train loss (one batch): 0.24163903295993805
Iter: 116 | Train loss (one batch): 0.24249565601348877
Iter: 117 | Train loss (one batch): 0.24990208446979523
Iter: 118 | Train loss (one batch): 0.24666284024715424
Iter: 119 | Train loss (one batch): 0.23259034752845764
Iter: 120 | Train loss (one batch): 0.2519562542438507
Iter: 121 | Train loss (one batch): 0.23458266258239746
Iter: 122 | Train loss (one batch): 0.23399905860424042
Iter: 123 | Train loss (one batch): 0.23360763490200043
Iter: 124 | Train loss (one batch): 0.20890729129314423
Iter: 125 | Train loss (one batch): 0.25394466519355774
Iter: 126 | Train loss (one batch): 0.24102701246738434
Iter: 127 | Train loss (one batch): 0.2618483603000641
Iter: 128 | Train loss (one batch): 0.2491549700498581
Iter: 129 | Train loss (one batch): 0.2230415940284729
Iter: 130 | Train loss (one batch): 0.24599964916706085
Iter: 131 | Train loss (one batch): 0.23213571310043335
Iter: 132 | Train loss (one batch): 0.2261543720960617
Iter: 133 | Train loss (one batch): 0.2210341840982437
Iter: 134 | Train loss (one batch): 0.21296659111976624
Iter: 135 | Train loss (one batch): 0.2202097624540329
Iter: 136 | Train loss (one batch): 0.23070751130580902
Iter: 137 | Train loss (one batch): 0.22539936006069183
Iter: 138 | Train loss (one batch): 0.21252718567848206
Iter: 139 | Train loss (one batch): 0.22392936050891876
Iter: 140 | Train loss (one batch): 0.22201496362686157
Iter: 141 | Train loss (one batch): 0.21222341060638428
Iter: 142 | Train loss (one batch): 0.2158016413450241
Iter: 143 | Train loss (one batch): 0.21161241829395294
Iter: 144 | Train loss (one batch): 0.23098215460777283
Iter: 145 | Train loss (one batch): 0.19068796932697296
Iter: 146 | Train loss (one batch): 0.20004397630691528
Iter: 147 | Train loss (one batch): 0.19457407295703888
Iter: 148 | Train loss (one batch): 0.1966153383255005
Iter: 149 | Train loss (one batch): 0.21259281039237976
Iter: 150 | Train loss (one batch): 0.21291054785251617
Iter: 151 | Train loss (one batch): 0.19299490749835968
Iter: 152 | Train loss (one batch): 0.19268332421779633
Iter: 153 | Train loss (one batch): 0.21802274882793427
Iter: 154 | Train loss (one batch): 0.18550221621990204
Iter: 155 | Train loss (one batch): 0.19945010542869568
Iter: 156 | Train loss (one batch): 0.19465185701847076
Iter: 157 | Train loss (one batch): 0.1934228539466858
Iter: 158 | Train loss (one batch): 0.19097857177257538
Iter: 159 | Train loss (one batch): 0.2032638043165207
Iter: 160 | Train loss (one batch): 0.19289234280586243
Iter: 161 | Train loss (one batch): 0.19139732420444489
Iter: 162 | Train loss (one batch): 0.18456657230854034
Iter: 163 | Train loss (one batch): 0.1844087392091751
Iter: 164 | Train loss (one batch): 0.19347958266735077
Iter: 165 | Train loss (one batch): 0.19159916043281555
Iter: 166 | Train loss (one batch): 0.17577265202999115
Iter: 167 | Train loss (one batch): 0.1686115264892578
Iter: 168 | Train loss (one batch): 0.17776520550251007
Iter: 169 | Train loss (one batch): 0.18611350655555725
Iter: 170 | Train loss (one batch): 0.18767355382442474
Iter: 171 | Train loss (one batch): 0.19163937866687775
Iter: 172 | Train loss (one batch): 0.19137586653232574
Iter: 173 | Train loss (one batch): 0.1835232824087143
Iter: 174 | Train loss (one batch): 0.17856504023075104
Iter: 175 | Train loss (one batch): 0.180129274725914
Iter: 176 | Train loss (one batch): 0.17036746442317963
Iter: 177 | Train loss (one batch): 0.1706790328025818
Iter: 178 | Train loss (one batch): 0.19115734100341797
Iter: 179 | Train loss (one batch): 0.17422324419021606
Iter: 180 | Train loss (one batch): 0.17572453618049622
Iter: 181 | Train loss (one batch): 0.17402096092700958
Iter: 182 | Train loss (one batch): 0.16609105467796326
Iter: 183 | Train loss (one batch): 0.15822874009609222
Iter: 184 | Train loss (one batch): 0.15200698375701904
Iter: 185 | Train loss (one batch): 0.17930477857589722
Iter: 186 | Train loss (one batch): 0.17575514316558838
Iter: 187 | Train loss (one batch): 0.15799714624881744
Iter: 188 | Train loss (one batch): 0.17010004818439484
Iter: 189 | Train loss (one batch): 0.1526034027338028
Iter: 190 | Train loss (one batch): 0.1633366197347641
Iter: 191 | Train loss (one batch): 0.15519924461841583
Iter: 192 | Train loss (one batch): 0.15234997868537903
Iter: 193 | Train loss (one batch): 0.14936524629592896
Iter: 194 | Train loss (one batch): 0.16698767244815826
Iter: 195 | Train loss (one batch): 0.1615038961172104
Iter: 196 | Train loss (one batch): 0.1684943288564682
Iter: 197 | Train loss (one batch): 0.16661100089550018
Iter: 198 | Train loss (one batch): 0.1503012627363205
Iter: 199 | Train loss (one batch): 0.14870546758174896
Iter: 200 | Train loss (one batch): 0.15919111669063568
Iter: 201 | Train loss (one batch): 0.15661901235580444
Iter: 202 | Train loss (one batch): 0.15686193108558655
Iter: 203 | Train loss (one batch): 0.15462377667427063
Iter: 204 | Train loss (one batch): 0.15568208694458008
Iter: 205 | Train loss (one batch): 0.1400686651468277
Iter: 206 | Train loss (one batch): 0.13650791347026825
Iter: 207 | Train loss (one batch): 0.1632988601922989
Iter: 208 | Train loss (one batch): 0.13261942565441132
Iter: 209 | Train loss (one batch): 0.1580016016960144
Iter: 210 | Train loss (one batch): 0.15476951003074646
Iter: 211 | Train loss (one batch): 0.1533193141222
Iter: 212 | Train loss (one batch): 0.14525753259658813
Iter: 213 | Train loss (one batch): 0.14944738149642944
Iter: 214 | Train loss (one batch): 0.1503092348575592
Iter: 215 | Train loss (one batch): 0.12920702993869781
Iter: 216 | Train loss (one batch): 0.15046143531799316
Iter: 217 | Train loss (one batch): 0.1441095471382141
Iter: 218 | Train loss (one batch): 0.14053204655647278
Iter: 219 | Train loss (one batch): 0.13094662129878998
Iter: 220 | Train loss (one batch): 0.1260373592376709
Iter: 221 | Train loss (one batch): 0.13433301448822021
Iter: 222 | Train loss (one batch): 0.15771977603435516
Iter: 223 | Train loss (one batch): 0.1431894302368164
Iter: 224 | Train loss (one batch): 0.13962650299072266
Iter: 225 | Train loss (one batch): 0.13056625425815582
Iter: 226 | Train loss (one batch): 0.14944426715373993
Iter: 227 | Train loss (one batch): 0.1356499195098877
Iter: 228 | Train loss (one batch): 0.1379774659872055
Iter: 229 | Train loss (one batch): 0.14333705604076385
Iter: 230 | Train loss (one batch): 0.12848614156246185
Iter: 231 | Train loss (one batch): 0.12146412581205368
Iter: 232 | Train loss (one batch): 0.1313677281141281
Iter: 233 | Train loss (one batch): 0.12973421812057495
Iter: 234 | Train loss (one batch): 0.13151314854621887
Iter: 235 | Train loss (one batch): 0.1460821032524109
Iter: 236 | Train loss (one batch): 0.1364532858133316
Iter: 237 | Train loss (one batch): 0.12846657633781433
Iter: 238 | Train loss (one batch): 0.11670678108930588
Iter: 239 | Train loss (one batch): 0.12499634921550751
Iter: 240 | Train loss (one batch): 0.12385255098342896
Iter: 241 | Train loss (one batch): 0.13123737275600433
Iter: 242 | Train loss (one batch): 0.1143510714173317
Iter: 243 | Train loss (one batch): 0.12169787287712097
Iter: 244 | Train loss (one batch): 0.12105742841959
Iter: 245 | Train loss (one batch): 0.12545795738697052
Iter: 246 | Train loss (one batch): 0.12182801961898804
Iter: 247 | Train loss (one batch): 0.11854331195354462
Iter: 248 | Train loss (one batch): 0.11952761560678482
Iter: 249 | Train loss (one batch): 0.11462855339050293
Iter: 250 | Train loss (one batch): 0.12342590093612671
Iter: 251 | Train loss (one batch): 0.11278600245714188
Iter: 252 | Train loss (one batch): 0.11606373637914658
Iter: 253 | Train loss (one batch): 0.10824492573738098
Iter: 254 | Train loss (one batch): 0.11753620207309723
Iter: 255 | Train loss (one batch): 0.10791750997304916
Iter: 256 | Train loss (one batch): 0.11716340482234955
Iter: 257 | Train loss (one batch): 0.11301965266466141
Iter: 258 | Train loss (one batch): 0.10432224720716476
Iter: 259 | Train loss (one batch): 0.11000029742717743
Iter: 260 | Train loss (one batch): 0.11580512672662735
Iter: 261 | Train loss (one batch): 0.10055390745401382
Iter: 262 | Train loss (one batch): 0.10153913497924805
Iter: 263 | Train loss (one batch): 0.1069670245051384
Iter: 264 | Train loss (one batch): 0.10022500157356262
Iter: 265 | Train loss (one batch): 0.09927898645401001
Iter: 266 | Train loss (one batch): 0.09743615984916687
Iter: 267 | Train loss (one batch): 0.10232068598270416
Iter: 268 | Train loss (one batch): 0.10979530215263367
Iter: 269 | Train loss (one batch): 0.11748050898313522
Iter: 270 | Train loss (one batch): 0.12572714686393738
Iter: 271 | Train loss (one batch): 0.10877957940101624
Iter: 272 | Train loss (one batch): 0.09883039444684982
Iter: 273 | Train loss (one batch): 0.09781591594219208
Iter: 274 | Train loss (one batch): 0.11391495168209076
Iter: 275 | Train loss (one batch): 0.1061871275305748
Iter: 276 | Train loss (one batch): 0.09649255126714706
Iter: 277 | Train loss (one batch): 0.0891597718000412
Iter: 278 | Train loss (one batch): 0.10216918587684631
Iter: 279 | Train loss (one batch): 0.09161761403083801
Iter: 280 | Train loss (one batch): 0.09856458008289337
Iter: 281 | Train loss (one batch): 0.09500105679035187
Iter: 282 | Train loss (one batch): 0.08912501484155655
Iter: 283 | Train loss (one batch): 0.09239758551120758
Iter: 284 | Train loss (one batch): 0.08435674756765366
Iter: 285 | Train loss (one batch): 0.08533196151256561
Iter: 286 | Train loss (one batch): 0.11787816882133484
Iter: 287 | Train loss (one batch): 0.10217820852994919
Iter: 288 | Train loss (one batch): 0.08720336109399796
Iter: 289 | Train loss (one batch): 0.08620087057352066
Iter: 290 | Train loss (one batch): 0.09374220669269562
Iter: 291 | Train loss (one batch): 0.08548291772603989
Iter: 292 | Train loss (one batch): 0.09026360511779785
Iter: 293 | Train loss (one batch): 0.08944332599639893
Iter: 294 | Train loss (one batch): 0.08739905804395676
Iter: 295 | Train loss (one batch): 0.08535666018724442
Iter: 296 | Train loss (one batch): 0.08285245299339294
Iter: 297 | Train loss (one batch): 0.0785808116197586
Iter: 298 | Train loss (one batch): 0.08957862854003906
Iter: 299 | Train loss (one batch): 0.08780379593372345
Iter: 300 | Train loss (one batch): 0.10006652772426605
Iter: 301 | Train loss (one batch): 0.08740904927253723
Iter: 302 | Train loss (one batch): 0.07336580008268356
Iter: 303 | Train loss (one batch): 0.07299600541591644
Iter: 304 | Train loss (one batch): 0.08498167246580124
Iter: 305 | Train loss (one batch): 0.09258797019720078
Iter: 306 | Train loss (one batch): 0.07757839560508728
Iter: 307 | Train loss (one batch): 0.0856841579079628
Iter: 308 | Train loss (one batch): 0.08731711655855179
Iter: 309 | Train loss (one batch): 0.08702550083398819
Iter: 310 | Train loss (one batch): 0.08451985567808151
Iter: 311 | Train loss (one batch): 0.07647435367107391
Iter: 312 | Train loss (one batch): 0.07939881086349487
Iter: 313 | Train loss (one batch): 0.07122160494327545
Iter: 314 | Train loss (one batch): 0.08350329101085663
Iter: 315 | Train loss (one batch): 0.07461921125650406
Iter: 316 | Train loss (one batch): 0.07582741975784302
Iter: 317 | Train loss (one batch): 0.07426751405000687
Iter: 318 | Train loss (one batch): 0.07472142577171326
Iter: 319 | Train loss (one batch): 0.06449385732412338
Iter: 320 | Train loss (one batch): 0.07512323558330536
Iter: 321 | Train loss (one batch): 0.06690278649330139
Iter: 322 | Train loss (one batch): 0.08465370535850525
Iter: 323 | Train loss (one batch): 0.07122346758842468
Iter: 324 | Train loss (one batch): 0.07389343529939651
Iter: 325 | Train loss (one batch): 0.06362562626600266
Iter: 326 | Train loss (one batch): 0.06875091791152954
Iter: 327 | Train loss (one batch): 0.06377146393060684
Iter: 328 | Train loss (one batch): 0.060783274471759796
Iter: 329 | Train loss (one batch): 0.06654395908117294
Iter: 330 | Train loss (one batch): 0.06829441338777542
Iter: 331 | Train loss (one batch): 0.0693293958902359
Iter: 332 | Train loss (one batch): 0.06896170973777771
Iter: 333 | Train loss (one batch): 0.06890896707773209
Iter: 334 | Train loss (one batch): 0.07717566192150116
Iter: 335 | Train loss (one batch): 0.0764668807387352
Iter: 336 | Train loss (one batch): 0.06871392577886581
Iter: 337 | Train loss (one batch): 0.06454161554574966
Iter: 338 | Train loss (one batch): 0.07874186336994171
Iter: 339 | Train loss (one batch): 0.07388438284397125
Iter: 340 | Train loss (one batch): 0.06784144788980484
Iter: 341 | Train loss (one batch): 0.06109163165092468
Iter: 342 | Train loss (one batch): 0.06158857420086861
Iter: 343 | Train loss (one batch): 0.06092462316155434
Iter: 344 | Train loss (one batch): 0.06689286231994629
Iter: 345 | Train loss (one batch): 0.06776370108127594
Iter: 346 | Train loss (one batch): 0.05403286963701248
Iter: 347 | Train loss (one batch): 0.05343968793749809
Iter: 348 | Train loss (one batch): 0.0491860955953598
Iter: 349 | Train loss (one batch): 0.07505173981189728
Iter: 350 | Train loss (one batch): 0.07634269446134567
Iter: 351 | Train loss (one batch): 0.07146942615509033
Iter: 352 | Train loss (one batch): 0.057545941323041916
Iter: 353 | Train loss (one batch): 0.05100312456488609
Iter: 354 | Train loss (one batch): 0.062060873955488205
Iter: 355 | Train loss (one batch): 0.05877643823623657
Iter: 356 | Train loss (one batch): 0.05672840029001236
Iter: 357 | Train loss (one batch): 0.06566272675991058
Iter: 358 | Train loss (one batch): 0.049117255955934525
Iter: 359 | Train loss (one batch): 0.05152217671275139
Iter: 360 | Train loss (one batch): 0.05017077922821045
Iter: 361 | Train loss (one batch): 0.0452035628259182
Iter: 362 | Train loss (one batch): 0.04878644272685051
Iter: 363 | Train loss (one batch): 0.06667608767747879
Iter: 364 | Train loss (one batch): 0.06211290881037712
Iter: 365 | Train loss (one batch): 0.06939081847667694
Iter: 366 | Train loss (one batch): 0.04292009770870209
Iter: 367 | Train loss (one batch): 0.04698823019862175
Iter: 368 | Train loss (one batch): 0.052944254130125046
Iter: 369 | Train loss (one batch): 0.057493340224027634
Iter: 370 | Train loss (one batch): 0.05096196010708809
Iter: 371 | Train loss (one batch): 0.04865612834692001
Iter: 372 | Train loss (one batch): 0.0531778484582901
Iter: 373 | Train loss (one batch): 0.05098411440849304
Iter: 374 | Train loss (one batch): 0.052671704441308975
Iter: 375 | Train loss (one batch): 0.050605978816747665
Iter: 376 | Train loss (one batch): 0.054733406752347946
Iter: 377 | Train loss (one batch): 0.04564601555466652
Iter: 378 | Train loss (one batch): 0.057835958898067474
Iter: 379 | Train loss (one batch): 0.04631025716662407
Iter: 380 | Train loss (one batch): 0.050155945122241974
Iter: 381 | Train loss (one batch): 0.04493138566613197
Iter: 382 | Train loss (one batch): 0.05115704610943794
Iter: 383 | Train loss (one batch): 0.04365569353103638
Experiment 59645
### Auxiliary Network : n_test_batches 40 ###
Iter 1 | Test loss (one batch): 0.03151821345090866
Loss(alpha 0.01) for Dopri integrator (one batch): 63.53292465209961
Loss(alpha 0.01) for Euler integrator (one batch): 62.58226776123047
Loss(alpha 0.01) for RK4 integrator (one batch): 63.26795959472656
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.7821350762527232
Iter 2 | Test loss (one batch): 0.01708710379898548
Loss(alpha 0.01) for Dopri integrator (one batch): 62.58589172363281
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.0
Iter 3 | Test loss (one batch): 0.014474809169769287
Loss(alpha 0.01) for Dopri integrator (one batch): 62.687713623046875
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.0
Iter 4 | Test loss (one batch): 0.029892025515437126
Loss(alpha 0.01) for Dopri integrator (one batch): 63.497215270996094
Loss(alpha 0.01) for Euler integrator (one batch): 62.48353576660156
Loss(alpha 0.01) for RK4 integrator (one batch): 63.09907531738281
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8641975308641975
Iter 5 | Test loss (one batch): 0.050448283553123474
Loss(alpha 0.01) for Dopri integrator (one batch): 65.34806823730469
Loss(alpha 0.01) for Euler integrator (one batch): 64.95166015625
Loss(alpha 0.01) for RK4 integrator (one batch): 63.605716705322266
Choice of integrator (one batch): euler
Auxiliary network predicted False
AUC of the choice (one batch): 0.5709876543209876
Iter 6 | Test loss (one batch): 0.04011624678969383
Loss(alpha 0.01) for Dopri integrator (one batch): 63.88740539550781
Loss(alpha 0.01) for Euler integrator (one batch): 62.878440856933594
Loss(alpha 0.01) for RK4 integrator (one batch): 63.69015884399414
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.7986111111111112
Iter 7 | Test loss (one batch): 0.04718460142612457
Loss(alpha 0.01) for Dopri integrator (one batch): 64.79563903808594
Loss(alpha 0.01) for Euler integrator (one batch): 64.06314086914062
Loss(alpha 0.01) for RK4 integrator (one batch): 63.774593353271484
Choice of integrator (one batch): euler
Auxiliary network predicted False
AUC of the choice (one batch): 0.6041666666666667
Iter 8 | Test loss (one batch): 0.03972332179546356
Loss(alpha 0.01) for Dopri integrator (one batch): 63.9654426574707
Loss(alpha 0.01) for Euler integrator (one batch): 62.58226776123047
Loss(alpha 0.01) for RK4 integrator (one batch): 63.605716705322266
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.873015873015873
Iter 9 | Test loss (one batch): 0.02249750867486
Loss(alpha 0.01) for Dopri integrator (one batch): 62.82265090942383
Loss(alpha 0.01) for Euler integrator (one batch): 61.7924690246582
Loss(alpha 0.01) for RK4 integrator (one batch): 62.50800323486328
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9409722222222222
Iter 10 | Test loss (one batch): 0.023001503199338913
Loss(alpha 0.01) for Dopri integrator (one batch): 62.87291717529297
Loss(alpha 0.01) for Euler integrator (one batch): 61.98991394042969
Loss(alpha 0.01) for RK4 integrator (one batch): 62.76131820678711
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9506172839506173
Iter 11 | Test loss (one batch): 0.03350144624710083
Loss(alpha 0.01) for Dopri integrator (one batch): 63.49721908569336
Loss(alpha 0.01) for Euler integrator (one batch): 62.38481521606445
Loss(alpha 0.01) for RK4 integrator (one batch): 63.01464080810547
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.7211328976034859
Iter 12 | Test loss (one batch): 0.021106412634253502
Loss(alpha 0.01) for Dopri integrator (one batch): 63.10702896118164
Loss(alpha 0.01) for Euler integrator (one batch): 61.49629211425781
Loss(alpha 0.01) for RK4 integrator (one batch): 62.50800323486328
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9907407407407408
Iter 13 | Test loss (one batch): 0.025380123406648636
Loss(alpha 0.01) for Dopri integrator (one batch): 63.10702896118164
Loss(alpha 0.01) for Euler integrator (one batch): 61.98991394042969
Loss(alpha 0.01) for RK4 integrator (one batch): 62.76131820678711
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9005847953216375
Iter 14 | Test loss (one batch): 0.05520154908299446
Loss(alpha 0.01) for Dopri integrator (one batch): 65.60424041748047
Loss(alpha 0.01) for Euler integrator (one batch): 65.24784088134766
Loss(alpha 0.01) for RK4 integrator (one batch): 65.5478286743164
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.3508771929824562
Iter 15 | Test loss (one batch): 0.05126460641622543
Loss(alpha 0.01) for Dopri integrator (one batch): 64.90190124511719
Loss(alpha 0.01) for Euler integrator (one batch): 64.45803833007812
Loss(alpha 0.01) for RK4 integrator (one batch): 64.6189956665039
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.5792592592592593
Iter 16 | Test loss (one batch): 0.01479281298816204
Loss(alpha 0.01) for Dopri integrator (one batch): 62.6388053894043
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 1.0
Iter 17 | Test loss (one batch): 0.03877227380871773
Loss(alpha 0.01) for Dopri integrator (one batch): 63.80618667602539
Loss(alpha 0.01) for Euler integrator (one batch): 63.075889587402344
Loss(alpha 0.01) for RK4 integrator (one batch): 63.521278381347656
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.845486111111111
Iter 18 | Test loss (one batch): 0.04351048544049263
Loss(alpha 0.01) for Dopri integrator (one batch): 63.57525634765625
Loss(alpha 0.01) for Euler integrator (one batch): 65.14911651611328
Loss(alpha 0.01) for RK4 integrator (one batch): 63.2679557800293
Choice of integrator (one batch): euler
Auxiliary network predicted False
AUC of the choice (one batch): 0.49673202614379086
Iter 19 | Test loss (one batch): 0.02865571156144142
Loss(alpha 0.01) for Dopri integrator (one batch): 63.10702896118164
Loss(alpha 0.01) for Euler integrator (one batch): 61.98991394042969
Loss(alpha 0.01) for RK4 integrator (one batch): 62.76131820678711
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.15432098765432098
Iter 20 | Test loss (one batch): 0.019592225551605225
Loss(alpha 0.01) for Dopri integrator (one batch): 62.82265090942383
Loss(alpha 0.01) for Euler integrator (one batch): 61.49629211425781
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9824561403508771
Iter 21 | Test loss (one batch): 0.026342233642935753
Loss(alpha 0.01) for Dopri integrator (one batch): 63.34114074707031
Loss(alpha 0.01) for Euler integrator (one batch): 61.98991394042969
Loss(alpha 0.01) for RK4 integrator (one batch): 62.845760345458984
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9122807017543859
Iter 22 | Test loss (one batch): 0.017335396260023117
Loss(alpha 0.01) for Dopri integrator (one batch): 62.6388053894043
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.0
Iter 23 | Test loss (one batch): 0.05277928337454796
Loss(alpha 0.01) for Dopri integrator (one batch): 65.21405792236328
Loss(alpha 0.01) for Euler integrator (one batch): 64.35931396484375
Loss(alpha 0.01) for RK4 integrator (one batch): 64.95674896240234
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.5277777777777778
Iter 24 | Test loss (one batch): 0.027314070612192154
Loss(alpha 0.01) for Dopri integrator (one batch): 63.34114074707031
Loss(alpha 0.01) for Euler integrator (one batch): 62.28609085083008
Loss(alpha 0.01) for RK4 integrator (one batch): 63.01464080810547
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8518518518518519
Iter 25 | Test loss (one batch): 0.04751729965209961
Loss(alpha 0.01) for Dopri integrator (one batch): 64.51171112060547
Loss(alpha 0.01) for Euler integrator (one batch): 63.865692138671875
Loss(alpha 0.01) for RK4 integrator (one batch): 64.28123474121094
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.6597222222222222
Iter 26 | Test loss (one batch): 0.025564251467585564
Loss(alpha 0.01) for Dopri integrator (one batch): 63.4191780090332
Loss(alpha 0.01) for Euler integrator (one batch): 62.28609085083008
Loss(alpha 0.01) for RK4 integrator (one batch): 63.09907913208008
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9166666666666667
Iter 27 | Test loss (one batch): 0.029200395569205284
Loss(alpha 0.01) for Dopri integrator (one batch): 63.26310729980469
Loss(alpha 0.01) for Euler integrator (one batch): 62.08864212036133
Loss(alpha 0.01) for RK4 integrator (one batch): 63.774600982666016
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8758169934640523
Iter 28 | Test loss (one batch): 0.02106362394988537
Loss(alpha 0.01) for Dopri integrator (one batch): 62.87291717529297
Loss(alpha 0.01) for Euler integrator (one batch): 61.69374084472656
Loss(alpha 0.01) for RK4 integrator (one batch): 62.50800323486328
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9473684210526316
Iter 29 | Test loss (one batch): 0.033681564033031464
Loss(alpha 0.01) for Dopri integrator (one batch): 63.57525634765625
Loss(alpha 0.01) for Euler integrator (one batch): 62.38481903076172
Loss(alpha 0.01) for RK4 integrator (one batch): 63.18351745605469
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8940972222222222
Iter 30 | Test loss (one batch): 0.035738132894039154
Loss(alpha 0.01) for Dopri integrator (one batch): 63.18506622314453
Loss(alpha 0.01) for Euler integrator (one batch): 63.075889587402344
Loss(alpha 0.01) for RK4 integrator (one batch): 63.43683624267578
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.9128540305010894
Iter 31 | Test loss (one batch): 0.03550145402550697
Loss(alpha 0.01) for Dopri integrator (one batch): 63.769683837890625
Loss(alpha 0.01) for Euler integrator (one batch): 62.878440856933594
Loss(alpha 0.01) for RK4 integrator (one batch): 63.774600982666016
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.7881944444444444
Iter 32 | Test loss (one batch): 0.035818081349134445
Loss(alpha 0.01) for Dopri integrator (one batch): 63.497215270996094
Loss(alpha 0.01) for Euler integrator (one batch): 62.68099594116211
Loss(alpha 0.01) for RK4 integrator (one batch): 63.35240173339844
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8690476190476191
Iter 33 | Test loss (one batch): 0.033900365233421326
Loss(alpha 0.01) for Dopri integrator (one batch): 63.57525634765625
Loss(alpha 0.01) for Euler integrator (one batch): 62.58226776123047
Loss(alpha 0.01) for RK4 integrator (one batch): 63.35239791870117
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.5815972222222222
Iter 34 | Test loss (one batch): 0.026052620261907578
Loss(alpha 0.01) for Dopri integrator (one batch): 63.10702896118164
Loss(alpha 0.01) for Euler integrator (one batch): 62.08863830566406
Loss(alpha 0.01) for RK4 integrator (one batch): 62.59244155883789
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8854166666666667
Iter 35 | Test loss (one batch): 0.029994959011673927
Loss(alpha 0.01) for Dopri integrator (one batch): 63.296165466308594
Loss(alpha 0.01) for Euler integrator (one batch): 62.1873664855957
Loss(alpha 0.01) for RK4 integrator (one batch): 63.01464080810547
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.8975694444444444
Iter 36 | Test loss (one batch): 0.05327240005135536
Loss(alpha 0.01) for Dopri integrator (one batch): 64.97993469238281
Loss(alpha 0.01) for Euler integrator (one batch): 64.26058959960938
Loss(alpha 0.01) for RK4 integrator (one batch): 64.95675659179688
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.6296296296296297
Iter 37 | Test loss (one batch): 0.04612309858202934
Loss(alpha 0.01) for Dopri integrator (one batch): 63.059410095214844
Loss(alpha 0.01) for Euler integrator (one batch): 64.85293579101562
Loss(alpha 0.01) for RK4 integrator (one batch): 65.04119873046875
Choice of integrator (one batch): euler
Auxiliary network predicted False
AUC of the choice (one batch): 0.6100217864923747
Iter 38 | Test loss (one batch): 0.03248051926493645
Loss(alpha 0.01) for Dopri integrator (one batch): 63.26310729980469
Loss(alpha 0.01) for Euler integrator (one batch): 62.286094665527344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.93020248413086
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.7152777777777778
Iter 39 | Test loss (one batch): 0.03435153886675835
Loss(alpha 0.01) for Dopri integrator (one batch): 63.454002380371094
Loss(alpha 0.01) for Euler integrator (one batch): 62.680992126464844
Loss(alpha 0.01) for RK4 integrator (one batch): 63.605716705322266
Choice of integrator (one batch): euler
Auxiliary network predicted True
AUC of the choice (one batch): 0.783625730994152
Iter 40 | Test loss (one batch): 0.06877490878105164
Loss(alpha 0.01) for Dopri integrator (one batch): 66.38461303710938
Loss(alpha 0.01) for Euler integrator (one batch): 66.72871398925781
Loss(alpha 0.01) for RK4 integrator (one batch): 66.56110382080078
Choice of integrator (one batch): euler
Auxiliary network predicted False
AUC of the choice (one batch): 0.1228070175438597
############### TOTAL ###############
Classification AUC : Dopri 0.7499 | Euler 0.7485 | RK4 0.7501
NFE (average): Dopri 72.05 | Euler 10.0 | RK4 40.0
Elapsed time (average): Dopri 0.5244853138923645 | Euler 0.132924485206604 | RK4 0.14319029450416565
############### Aux Net Average ###############
AUC of the choice 0.7536 | Choice of Dopri5 0 | Euler 40 | RK4 0
Aux Net Runtime: 1601544744.8838
