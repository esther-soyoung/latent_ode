/home/soyoung/latent_ode1/train_aux.py
train_aux.py --niters 5 -n 8000 -l 20 --latent-ode --z0-encoder rnn --dataset physionet --rec-dims 40 --rec-layers 3 --gen-layers 3 --units 50 --gru-units 50 --quantization 0.016 --classif --gpu 1
### Auxiliary Network : step size 0.1###
Iter: 1 | Train loss (one batch): 40824.91015625
Iter: 2 | Train loss (one batch): 51424.25
Iter: 3 | Train loss (one batch): 59814.625
Iter: 4 | Train loss (one batch): 66164.875
Iter: 5 | Train loss (one batch): 38297.12890625
Iter: 6 | Train loss (one batch): 63245.62109375
Iter: 7 | Train loss (one batch): 22607.791015625
Iter: 8 | Train loss (one batch): 42163.7421875
Iter: 9 | Train loss (one batch): 50111.01171875
Iter: 10 | Train loss (one batch): 52281.3125
Iter: 11 | Train loss (one batch): 54365.02734375
Iter: 12 | Train loss (one batch): 54365.01171875
Iter: 13 | Train loss (one batch): 65489.58984375
Iter: 14 | Train loss (one batch): 60184.86328125
Iter: 15 | Train loss (one batch): 65827.984375
Iter: 16 | Train loss (one batch): 52493.31640625
Iter: 17 | Train loss (one batch): 37712.30078125
Iter: 18 | Train loss (one batch): 29814.166015625
Iter: 19 | Train loss (one batch): 66999.0078125
Iter: 20 | Train loss (one batch): 54160.10546875
Iter: 21 | Train loss (one batch): 43204.78515625
Iter: 22 | Train loss (one batch): 39721.12890625
Iter: 23 | Train loss (one batch): 50989.9921875
Iter: 24 | Train loss (one batch): 55777.01953125
Iter: 25 | Train loss (one batch): 50110.72265625
Iter: 26 | Train loss (one batch): 32659.654296875
Iter: 27 | Train loss (one batch): 53540.89453125
Iter: 28 | Train loss (one batch): 40551.45703125
Iter: 29 | Train loss (one batch): 64806.92578125
Iter: 30 | Train loss (one batch): 61823.609375
Iter: 31 | Train loss (one batch): 63943.9765625
Iter: 32 | Train loss (one batch): 50771.3359375
Iter: 33 | Train loss (one batch): 48989.3203125
Iter: 34 | Train loss (one batch): 60552.28125
Iter: 35 | Train loss (one batch): 33664.55859375
Iter: 36 | Train loss (one batch): 43204.21875
Iter: 37 | Train loss (one batch): 54364.0546875
Iter: 38 | Train loss (one batch): 42162.98046875
Iter: 39 | Train loss (one batch): 43968.81640625
Iter: 40 | Train loss (one batch): 28673.7734375
Iter: 41 | Train loss (one batch): 26245.982421875
Iter: 42 | Train loss (one batch): 39439.4921875
Iter: 43 | Train loss (one batch): 52702.984375
Iter: 44 | Train loss (one batch): 38295.8203125
Iter: 45 | Train loss (one batch): 65487.3828125
Iter: 46 | Train loss (one batch): 41632.15234375
Iter: 47 | Train loss (one batch): 57924.953125
Iter: 48 | Train loss (one batch): 60182.53515625
Iter: 49 | Train loss (one batch): 42685.4921875
Iter: 50 | Train loss (one batch): 64804.34375
Iter: 51 | Train loss (one batch): 38295.23046875
Iter: 52 | Train loss (one batch): 64803.4453125
Iter: 53 | Train loss (one batch): 59811.25
Iter: 54 | Train loss (one batch): 41631.02734375
Iter: 55 | Train loss (one batch): 58114.32421875
Iter: 56 | Train loss (one batch): 42684.08984375
Iter: 57 | Train loss (one batch): 39717.96484375
Iter: 58 | Train loss (one batch): 67653.6875
Iter: 59 | Train loss (one batch): 46899.4375
Iter: 60 | Train loss (one batch): 43457.1484375
Iter: 61 | Train loss (one batch): 38293.34375
Iter: 62 | Train loss (one batch): 41894.51171875
Iter: 63 | Train loss (one batch): 47369.51171875
Iter: 64 | Train loss (one batch): 62174.11328125
Iter: 65 | Train loss (one batch): 40545.9921875
Iter: 66 | Train loss (one batch): 48755.49609375
Iter: 67 | Train loss (one batch): 58680.390625
Iter: 68 | Train loss (one batch): 69110.078125
Iter: 69 | Train loss (one batch): 41088.84375
Iter: 70 | Train loss (one batch): 64106.18359375
Iter: 71 | Train loss (one batch): 22603.41015625
Iter: 72 | Train loss (one batch): 40815.7421875
Iter: 73 | Train loss (one batch): 49655.40234375
Iter: 74 | Train loss (one batch): 56162.515625
Iter: 75 | Train loss (one batch): 54962.1875
Iter: 76 | Train loss (one batch): 56161.1484375
Iter: 77 | Train loss (one batch): 66480.578125
Iter: 78 | Train loss (one batch): 62342.97265625
Iter: 79 | Train loss (one batch): 58291.046875
Iter: 80 | Train loss (one batch): 51189.23828125
Iter: 81 | Train loss (one batch): 40537.59765625
Iter: 82 | Train loss (one batch): 29803.640625
Iter: 83 | Train loss (one batch): 69893.5078125
Iter: 84 | Train loss (one batch): 53517.8984375
Iter: 85 | Train loss (one batch): 38857.234375
Iter: 86 | Train loss (one batch): 39981.125
Iter: 87 | Train loss (one batch): 57707.92578125
Iter: 88 | Train loss (one batch): 52254.08203125
Iter: 89 | Train loss (one batch): 53302.4453125
Iter: 90 | Train loss (one batch): 33312.13671875
Iter: 91 | Train loss (one batch): 53297.98046875
Iter: 92 | Train loss (one batch): 39415.7734375
Iter: 93 | Train loss (one batch): 65949.2109375
Iter: 94 | Train loss (one batch): 62138.46875
Iter: 95 | Train loss (one batch): 68747.75
Iter: 96 | Train loss (one batch): 50071.37109375
Iter: 97 | Train loss (one batch): 48493.6484375
Iter: 98 | Train loss (one batch): 61231.5390625
Iter: 99 | Train loss (one batch): 34928.171875
Iter: 100 | Train loss (one batch): 46385.046875
Iter: 101 | Train loss (one batch): 59941.05078125
Iter: 102 | Train loss (one batch): 38257.76171875
Iter: 103 | Train loss (one batch): 43922.19140625
Iter: 104 | Train loss (one batch): 28640.54296875
Iter: 105 | Train loss (one batch): 27049.970703125
Iter: 106 | Train loss (one batch): 35233.2421875
Iter: 107 | Train loss (one batch): 53057.53515625
Iter: 108 | Train loss (one batch): 39667.76953125
Iter: 109 | Train loss (one batch): 64028.3828125
Iter: 110 | Train loss (one batch): 40215.72265625
Iter: 111 | Train loss (one batch): 55686.7265625
Iter: 112 | Train loss (one batch): 61361.97265625
Iter: 113 | Train loss (one batch): 50686.08203125
Iter: 114 | Train loss (one batch): 64863.78515625
Iter: 115 | Train loss (one batch): 40206.98828125
Iter: 116 | Train loss (one batch): 66196.7421875
Iter: 117 | Train loss (one batch): 62417.07421875
Iter: 118 | Train loss (one batch): 36742.6328125
Iter: 119 | Train loss (one batch): 58930.546875
Iter: 120 | Train loss (one batch): 43876.6328125
Iter: 121 | Train loss (one batch): 40181.40625
Iter: 122 | Train loss (one batch): 66835.859375
Iter: 123 | Train loss (one batch): 47253.7578125
Iter: 124 | Train loss (one batch): 42309.328125
Iter: 125 | Train loss (one batch): 37022.90625
Iter: 126 | Train loss (one batch): 41512.12890625
Iter: 127 | Train loss (one batch): 47469.62890625
Iter: 128 | Train loss (one batch): 62338.4453125
Iter: 129 | Train loss (one batch): 40679.265625
Iter: 130 | Train loss (one batch): 51455.4765625
Iter: 131 | Train loss (one batch): 58271.390625
Iter: 132 | Train loss (one batch): 64394.96875
Iter: 133 | Train loss (one batch): 40685.0703125
Iter: 134 | Train loss (one batch): 60319.99609375
Iter: 135 | Train loss (one batch): 22032.416015625
Iter: 136 | Train loss (one batch): 40109.328125
Iter: 137 | Train loss (one batch): 50985.75
Iter: 138 | Train loss (one batch): 55142.92578125
Iter: 139 | Train loss (one batch): 54302.72265625
Iter: 140 | Train loss (one batch): 63648.94921875
Iter: 141 | Train loss (one batch): 66649.90625
Iter: 142 | Train loss (one batch): 61336.8046875
Iter: 143 | Train loss (one batch): 57218.859375
Iter: 144 | Train loss (one batch): 51774.3046875
Iter: 145 | Train loss (one batch): 38663.37890625
Iter: 146 | Train loss (one batch): 30770.0859375
Iter: 147 | Train loss (one batch): 70106.5625
Iter: 148 | Train loss (one batch): 53978.95703125
Iter: 149 | Train loss (one batch): 43169.8359375
Iter: 150 | Train loss (one batch): 40260.3046875
Iter: 151 | Train loss (one batch): 48210.5703125
Iter: 152 | Train loss (one batch): 54365.73828125
Iter: 153 | Train loss (one batch): 53350.51953125
Iter: 154 | Train loss (one batch): 34001.59375
Iter: 155 | Train loss (one batch): 53933.88671875
Iter: 156 | Train loss (one batch): 39384.56640625
Iter: 157 | Train loss (one batch): 63008.078125
Iter: 158 | Train loss (one batch): 60534.9453125
Iter: 159 | Train loss (one batch): 68347.625
Iter: 160 | Train loss (one batch): 50577.24609375
Iter: 161 | Train loss (one batch): 48512.67578125
Iter: 162 | Train loss (one batch): 57897.1171875
Iter: 163 | Train loss (one batch): 32955.76953125
Iter: 164 | Train loss (one batch): 44237.11328125
Iter: 165 | Train loss (one batch): 60042.6015625
Iter: 166 | Train loss (one batch): 39593.69140625
Iter: 167 | Train loss (one batch): 42686.9921875
Iter: 168 | Train loss (one batch): 32966.33984375
Iter: 169 | Train loss (one batch): 27595.39453125
Iter: 170 | Train loss (one batch): 37486.21875
Iter: 171 | Train loss (one batch): 51410.2421875
Iter: 172 | Train loss (one batch): 48805.59375
Iter: 173 | Train loss (one batch): 62977.19140625
Iter: 174 | Train loss (one batch): 43636.4609375
Iter: 175 | Train loss (one batch): 54594.9140625
Iter: 176 | Train loss (one batch): 60221.3046875
Iter: 177 | Train loss (one batch): 50279.05859375
Iter: 178 | Train loss (one batch): 58010.4453125
Iter: 179 | Train loss (one batch): 39708.84375
Iter: 180 | Train loss (one batch): 65833.4296875
Iter: 181 | Train loss (one batch): 57166.015625
Iter: 182 | Train loss (one batch): 27417.212890625
Iter: 183 | Train loss (one batch): 59333.49609375
Iter: 184 | Train loss (one batch): 43190.40625
Iter: 185 | Train loss (one batch): 40068.76171875
Iter: 186 | Train loss (one batch): 65057.9921875
Iter: 187 | Train loss (one batch): 47718.17578125
Iter: 188 | Train loss (one batch): 42058.890625
Iter: 189 | Train loss (one batch): 38776.37890625
Iter: 190 | Train loss (one batch): 40070.1015625
Iter: 191 | Train loss (one batch): 47000.6640625
Iter: 192 | Train loss (one batch): 60053.859375
Iter: 193 | Train loss (one batch): 39559.9140625
Iter: 194 | Train loss (one batch): 50710.4140625
Iter: 195 | Train loss (one batch): 59314.61328125
Iter: 196 | Train loss (one batch): 62799.03125
Iter: 197 | Train loss (one batch): 41178.81640625
Iter: 198 | Train loss (one batch): 65395.625
Iter: 199 | Train loss (one batch): 20754.87109375
Iter: 200 | Train loss (one batch): 41302.1953125
Iter: 201 | Train loss (one batch): 50263.3671875
Iter: 202 | Train loss (one batch): 54443.6953125
Iter: 203 | Train loss (one batch): 52594.59375
Iter: 204 | Train loss (one batch): 59740.1328125
Iter: 205 | Train loss (one batch): 63751.453125
Iter: 206 | Train loss (one batch): 60030.58984375
Iter: 207 | Train loss (one batch): 59539.08203125
Iter: 208 | Train loss (one batch): 52666.5234375
Iter: 209 | Train loss (one batch): 37091.61328125
Iter: 210 | Train loss (one batch): 28367.439453125
Iter: 211 | Train loss (one batch): 66880.2421875
Iter: 212 | Train loss (one batch): 52874.54296875
Iter: 213 | Train loss (one batch): 37188.54296875
Iter: 214 | Train loss (one batch): 37585.765625
Iter: 215 | Train loss (one batch): 48437.92578125
Iter: 216 | Train loss (one batch): 49220.30078125
Iter: 217 | Train loss (one batch): 53182.84765625
Iter: 218 | Train loss (one batch): 32614.13671875
Iter: 219 | Train loss (one batch): 52279.671875
Iter: 220 | Train loss (one batch): 38293.80078125
Iter: 221 | Train loss (one batch): 59961.87890625
Iter: 222 | Train loss (one batch): 58829.21484375
Iter: 223 | Train loss (one batch): 68233.828125
Iter: 224 | Train loss (one batch): 46797.05859375
Iter: 225 | Train loss (one batch): 53431.98828125
Iter: 226 | Train loss (one batch): 58693.37109375
Iter: 227 | Train loss (one batch): 34146.29296875
Iter: 228 | Train loss (one batch): 42093.8125
Iter: 229 | Train loss (one batch): 63826.875
Iter: 230 | Train loss (one batch): 37935.1875
Iter: 231 | Train loss (one batch): 42133.55859375
Iter: 232 | Train loss (one batch): 29679.61328125
Iter: 233 | Train loss (one batch): 26976.125
Iter: 234 | Train loss (one batch): 35100.19921875
Iter: 235 | Train loss (one batch): 50151.15234375
Iter: 236 | Train loss (one batch): 40257.8515625
Iter: 237 | Train loss (one batch): 60463.14453125
Iter: 238 | Train loss (one batch): 40256.59375
Iter: 239 | Train loss (one batch): 53175.4765625
Iter: 240 | Train loss (one batch): 58972.80859375
Iter: 241 | Train loss (one batch): 47614.7890625
Iter: 242 | Train loss (one batch): 60888.7421875
Iter: 243 | Train loss (one batch): 36055.91796875
Iter: 244 | Train loss (one batch): 60035.875
Iter: 245 | Train loss (one batch): 56335.41796875
Iter: 246 | Train loss (one batch): 28994.712890625
Iter: 247 | Train loss (one batch): 55754.1484375
Iter: 248 | Train loss (one batch): 41534.21875
Iter: 249 | Train loss (one batch): 36284.1640625
Iter: 250 | Train loss (one batch): 62694.859375
Iter: 251 | Train loss (one batch): 44817.71484375
Iter: 252 | Train loss (one batch): 42768.46484375
Iter: 253 | Train loss (one batch): 36941.94140625
Iter: 254 | Train loss (one batch): 39927.43359375
Iter: 255 | Train loss (one batch): 45374.0703125
Iter: 256 | Train loss (one batch): 58015.34375
Iter: 257 | Train loss (one batch): 38603.7578125
Iter: 258 | Train loss (one batch): 52666.21875
Iter: 259 | Train loss (one batch): 55714.515625
Iter: 260 | Train loss (one batch): 59695.37109375
Iter: 261 | Train loss (one batch): 35567.71875
Iter: 262 | Train loss (one batch): 57038.03125
Iter: 263 | Train loss (one batch): 22252.21875
Iter: 264 | Train loss (one batch): 38383.8125
Iter: 265 | Train loss (one batch): 45985.75
Iter: 266 | Train loss (one batch): 48960.31640625
Iter: 267 | Train loss (one batch): 49611.1171875
Iter: 268 | Train loss (one batch): 48925.08203125
Iter: 269 | Train loss (one batch): 60211.75390625
Iter: 270 | Train loss (one batch): 55930.09765625
Iter: 271 | Train loss (one batch): 57717.62109375
Iter: 272 | Train loss (one batch): 45059.91015625
Iter: 273 | Train loss (one batch): 37495.44921875
Iter: 274 | Train loss (one batch): 29108.2578125
Iter: 275 | Train loss (one batch): 63689.18359375
Iter: 276 | Train loss (one batch): 49870.12890625
Iter: 277 | Train loss (one batch): 39684.578125
Iter: 278 | Train loss (one batch): 40772.328125
Iter: 279 | Train loss (one batch): 43648.0703125
Iter: 280 | Train loss (one batch): 46100.27734375
Iter: 281 | Train loss (one batch): 46344.58984375
Iter: 282 | Train loss (one batch): 31302.423828125
Iter: 283 | Train loss (one batch): 47321.86328125
Iter: 284 | Train loss (one batch): 36997.44140625
Iter: 285 | Train loss (one batch): 53569.2421875
Iter: 286 | Train loss (one batch): 56881.6640625
Iter: 287 | Train loss (one batch): 63724.0
Iter: 288 | Train loss (one batch): 46433.1484375
Iter: 289 | Train loss (one batch): 52105.63671875
Iter: 290 | Train loss (one batch): 51244.40234375
Iter: 291 | Train loss (one batch): 34010.3203125
Iter: 292 | Train loss (one batch): 37377.4453125
Iter: 293 | Train loss (one batch): 52277.296875
Iter: 294 | Train loss (one batch): 37760.91796875
Iter: 295 | Train loss (one batch): 40128.47265625
Iter: 296 | Train loss (one batch): 27891.544921875
Iter: 297 | Train loss (one batch): 26953.4140625
Iter: 298 | Train loss (one batch): 38437.30078125
Iter: 299 | Train loss (one batch): 45956.3671875
Iter: 300 | Train loss (one batch): 50049.3203125
Iter: 301 | Train loss (one batch): 55977.96484375
Iter: 302 | Train loss (one batch): 38742.0546875
Iter: 303 | Train loss (one batch): 52235.17578125
Iter: 304 | Train loss (one batch): 54551.3203125
Iter: 305 | Train loss (one batch): 45962.984375
Iter: 306 | Train loss (one batch): 56135.99609375
Iter: 307 | Train loss (one batch): 36015.83984375
Iter: 308 | Train loss (one batch): 53606.34765625
Iter: 309 | Train loss (one batch): 51947.04296875
Iter: 310 | Train loss (one batch): 27963.353515625
Iter: 311 | Train loss (one batch): 50944.45703125
Iter: 312 | Train loss (one batch): 39329.90234375
Iter: 313 | Train loss (one batch): 34631.44140625
Iter: 314 | Train loss (one batch): 58418.8828125
Iter: 315 | Train loss (one batch): 42155.96484375
Iter: 316 | Train loss (one batch): 39493.26171875
Iter: 317 | Train loss (one batch): 35833.55078125
Iter: 318 | Train loss (one batch): 39768.75390625
Iter: 319 | Train loss (one batch): 41994.05859375
Iter: 320 | Train loss (one batch): 52234.78125
Iter: 321 | Train loss (one batch): 36641.60546875
Iter: 322 | Train loss (one batch): 44737.0
Iter: 323 | Train loss (one batch): 50254.44140625
Iter: 324 | Train loss (one batch): 55273.5078125
Iter: 325 | Train loss (one batch): 38396.10546875
Iter: 326 | Train loss (one batch): 53454.84375
Iter: 327 | Train loss (one batch): 25796.5
Iter: 328 | Train loss (one batch): 38304.40625
Iter: 329 | Train loss (one batch): 42394.04296875
Iter: 330 | Train loss (one batch): 47004.55078125
Iter: 331 | Train loss (one batch): 48228.69921875
Iter: 332 | Train loss (one batch): 52961.11328125
Iter: 333 | Train loss (one batch): 54445.4765625
Iter: 334 | Train loss (one batch): 53139.50390625
Iter: 335 | Train loss (one batch): 52686.58984375
Iter: 336 | Train loss (one batch): 44767.29296875
Iter: 337 | Train loss (one batch): 36286.10546875
Iter: 338 | Train loss (one batch): 31610.439453125
Iter: 339 | Train loss (one batch): 58972.5
Iter: 340 | Train loss (one batch): 48074.53515625
Iter: 341 | Train loss (one batch): 36688.85546875
Iter: 342 | Train loss (one batch): 40564.640625
Iter: 343 | Train loss (one batch): 42051.0
Iter: 344 | Train loss (one batch): 43805.94921875
Iter: 345 | Train loss (one batch): 43909.921875
Iter: 346 | Train loss (one batch): 32235.2421875
Iter: 347 | Train loss (one batch): 46986.98828125
Iter: 348 | Train loss (one batch): 37844.71484375
Iter: 349 | Train loss (one batch): 53581.89453125
Iter: 350 | Train loss (one batch): 53001.2421875
Iter: 351 | Train loss (one batch): 53096.92578125
Iter: 352 | Train loss (one batch): 46594.45703125
Iter: 353 | Train loss (one batch): 42803.7109375
Iter: 354 | Train loss (one batch): 52254.97265625
Iter: 355 | Train loss (one batch): 33628.5625
Iter: 356 | Train loss (one batch): 38179.2578125
Iter: 357 | Train loss (one batch): 54631.52734375
Iter: 358 | Train loss (one batch): 37909.03125
Iter: 359 | Train loss (one batch): 40102.7109375
Iter: 360 | Train loss (one batch): 31317.595703125
Iter: 361 | Train loss (one batch): 31833.0703125
Iter: 362 | Train loss (one batch): 34750.83984375
Iter: 363 | Train loss (one batch): 45154.25
Iter: 364 | Train loss (one batch): 36195.04296875
Iter: 365 | Train loss (one batch): 52484.54296875
Iter: 366 | Train loss (one batch): 38531.59765625
Iter: 367 | Train loss (one batch): 49600.16796875
Iter: 368 | Train loss (one batch): 52263.796875
Iter: 369 | Train loss (one batch): 46991.99609375
Iter: 370 | Train loss (one batch): 54602.015625
Iter: 371 | Train loss (one batch): 37718.8359375
Iter: 372 | Train loss (one batch): 56811.0703125
Iter: 373 | Train loss (one batch): 49604.86328125
Iter: 374 | Train loss (one batch): 37310.796875
Iter: 375 | Train loss (one batch): 47702.9609375
Iter: 376 | Train loss (one batch): 40318.6953125
Iter: 377 | Train loss (one batch): 35825.171875
Iter: 378 | Train loss (one batch): 55246.15625
Iter: 379 | Train loss (one batch): 41971.1328125
Iter: 380 | Train loss (one batch): 39342.51171875
Iter: 381 | Train loss (one batch): 34774.671875
Iter: 382 | Train loss (one batch): 38380.33984375
Iter: 383 | Train loss (one batch): 44141.86328125
Experiment 12816
### Auxiliary Network : n_test_batches 40 ###
Iter 1 | Test loss (one batch): 44084.765625
Loss(alpha 0.01) for Dopri integrator (one batch): 1500046.375
Loss(alpha 0.01) for Euler integrator (one batch): 1700043.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1800043.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7712418300653594
Iter 2 | Test loss (one batch): 21621.703125
Loss(alpha 0.01) for Dopri integrator (one batch): 62.22270584106445
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.0
Iter 3 | Test loss (one batch): 22356.3125
Loss(alpha 0.01) for Dopri integrator (one batch): 62.22270584106445
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.0
Iter 4 | Test loss (one batch): 35298.125
Loss(alpha 0.01) for Dopri integrator (one batch): 500056.875
Loss(alpha 0.01) for Euler integrator (one batch): 1200048.625
Loss(alpha 0.01) for RK4 integrator (one batch): 800054.125
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9290123456790124
Iter 5 | Test loss (one batch): 41754.81640625
Loss(alpha 0.01) for Dopri integrator (one batch): 1300048.5
Loss(alpha 0.01) for Euler integrator (one batch): 1500045.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1400047.25
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.5277777777777778
Iter 6 | Test loss (one batch): 43092.640625
Loss(alpha 0.01) for Dopri integrator (one batch): 1800043.125
Loss(alpha 0.01) for Euler integrator (one batch): 1500045.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1400047.75
Choice of integrator (one batch): rk4
Auxiliary network predicted True
AUC of the choice (one batch): 0.7899305555555556
Iter 7 | Test loss (one batch): 61713.1015625
Loss(alpha 0.01) for Dopri integrator (one batch): 3600024.5
Loss(alpha 0.01) for Euler integrator (one batch): 3600024.5
Loss(alpha 0.01) for RK4 integrator (one batch): 3600024.5
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.5121527777777777
Iter 8 | Test loss (one batch): 40171.31640625
Loss(alpha 0.01) for Dopri integrator (one batch): 900053.4375
Loss(alpha 0.01) for Euler integrator (one batch): 1700043.5
Loss(alpha 0.01) for RK4 integrator (one batch): 900053.4375
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8253968253968254
Iter 9 | Test loss (one batch): 31968.083984375
Loss(alpha 0.01) for Dopri integrator (one batch): 600055.875
Loss(alpha 0.01) for Euler integrator (one batch): 600055.4375
Loss(alpha 0.01) for RK4 integrator (one batch): 600055.9375
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9513888888888888
Iter 10 | Test loss (one batch): 31635.625
Loss(alpha 0.01) for Dopri integrator (one batch): 400057.9375
Loss(alpha 0.01) for Euler integrator (one batch): 600055.4375
Loss(alpha 0.01) for RK4 integrator (one batch): 600055.9375
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9444444444444444
Iter 11 | Test loss (one batch): 38577.6171875
Loss(alpha 0.01) for Dopri integrator (one batch): 1000052.5
Loss(alpha 0.01) for Euler integrator (one batch): 1300047.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1000052.5
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7015250544662308
Iter 12 | Test loss (one batch): 37494.2265625
Loss(alpha 0.01) for Dopri integrator (one batch): 1100051.25
Loss(alpha 0.01) for Euler integrator (one batch): 700054.4375
Loss(alpha 0.01) for RK4 integrator (one batch): 1000052.25
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9135802469135803
Iter 13 | Test loss (one batch): 27781.544921875
Loss(alpha 0.01) for Dopri integrator (one batch): 300058.96875
Loss(alpha 0.01) for Euler integrator (one batch): 400057.5
Loss(alpha 0.01) for RK4 integrator (one batch): 300059.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9707602339181287
Iter 14 | Test loss (one batch): 61322.625
Loss(alpha 0.01) for Dopri integrator (one batch): 3600024.25
Loss(alpha 0.01) for Euler integrator (one batch): 3600024.25
Loss(alpha 0.01) for RK4 integrator (one batch): 3800022.25
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.368421052631579
Iter 15 | Test loss (one batch): 40613.2421875
Loss(alpha 0.01) for Dopri integrator (one batch): 1100051.0
Loss(alpha 0.01) for Euler integrator (one batch): 1400046.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1200050.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7037037037037037
Iter 16 | Test loss (one batch): 21058.0234375
Loss(alpha 0.01) for Dopri integrator (one batch): 62.22270584106445
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 1.0
Iter 17 | Test loss (one batch): 45095.671875
Loss(alpha 0.01) for Dopri integrator (one batch): 1900042.0
Loss(alpha 0.01) for Euler integrator (one batch): 1600044.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1800043.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8177083333333334
Iter 18 | Test loss (one batch): 57632.93359375
Loss(alpha 0.01) for Dopri integrator (one batch): 3200028.5
Loss(alpha 0.01) for Euler integrator (one batch): 3000030.25
Loss(alpha 0.01) for RK4 integrator (one batch): 3300027.5
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.5381263616557734
Iter 19 | Test loss (one batch): 34408.37109375
Loss(alpha 0.01) for Dopri integrator (one batch): 600056.0
Loss(alpha 0.01) for Euler integrator (one batch): 600055.25
Loss(alpha 0.01) for RK4 integrator (one batch): 600056.0625
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.12345679012345678
Iter 20 | Test loss (one batch): 24940.32421875
Loss(alpha 0.01) for Dopri integrator (one batch): 300058.9375
Loss(alpha 0.01) for Euler integrator (one batch): 100060.3828125
Loss(alpha 0.01) for RK4 integrator (one batch): 100061.2578125
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9941520467836257
Iter 21 | Test loss (one batch): 31865.814453125
Loss(alpha 0.01) for Dopri integrator (one batch): 800054.4375
Loss(alpha 0.01) for Euler integrator (one batch): 600055.375
Loss(alpha 0.01) for RK4 integrator (one batch): 600056.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8947368421052632
Iter 22 | Test loss (one batch): 21030.423828125
Loss(alpha 0.01) for Dopri integrator (one batch): 62.22270584106445
Loss(alpha 0.01) for Euler integrator (one batch): 61.39756774902344
Loss(alpha 0.01) for RK4 integrator (one batch): 62.25468444824219
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.0
Iter 23 | Test loss (one batch): 42036.515625
Loss(alpha 0.01) for Dopri integrator (one batch): 1600045.125
Loss(alpha 0.01) for Euler integrator (one batch): 1400046.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1400047.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7654320987654321
Iter 24 | Test loss (one batch): 33747.47265625
Loss(alpha 0.01) for Dopri integrator (one batch): 600056.125
Loss(alpha 0.01) for Euler integrator (one batch): 600055.125
Loss(alpha 0.01) for RK4 integrator (one batch): 600056.25
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9166666666666666
Iter 25 | Test loss (one batch): 50620.00390625
Loss(alpha 0.01) for Dopri integrator (one batch): 2300037.75
Loss(alpha 0.01) for Euler integrator (one batch): 2300037.5
Loss(alpha 0.01) for RK4 integrator (one batch): 2400036.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.671875
Iter 26 | Test loss (one batch): 38028.76171875
Loss(alpha 0.01) for Dopri integrator (one batch): 1200050.25
Loss(alpha 0.01) for Euler integrator (one batch): 1000050.75
Loss(alpha 0.01) for RK4 integrator (one batch): 900053.4375
Choice of integrator (one batch): rk4
Auxiliary network predicted True
AUC of the choice (one batch): 0.8827160493827161
Iter 27 | Test loss (one batch): 45555.44921875
Loss(alpha 0.01) for Dopri integrator (one batch): 1800042.75
Loss(alpha 0.01) for Euler integrator (one batch): 1900041.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1800042.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8649237472766884
Iter 28 | Test loss (one batch): 25232.841796875
Loss(alpha 0.01) for Dopri integrator (one batch): 300058.90625
Loss(alpha 0.01) for Euler integrator (one batch): 200059.140625
Loss(alpha 0.01) for RK4 integrator (one batch): 100061.2578125
Choice of integrator (one batch): rk4
Auxiliary network predicted True
AUC of the choice (one batch): 0.9941520467836257
Iter 29 | Test loss (one batch): 31445.001953125
Loss(alpha 0.01) for Dopri integrator (one batch): 600056.0
Loss(alpha 0.01) for Euler integrator (one batch): 300058.375
Loss(alpha 0.01) for RK4 integrator (one batch): 600056.25
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.9635416666666666
Iter 30 | Test loss (one batch): 47515.90234375
Loss(alpha 0.01) for Dopri integrator (one batch): 2200038.75
Loss(alpha 0.01) for Euler integrator (one batch): 1700043.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1800043.125
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7494553376906318
Iter 31 | Test loss (one batch): 43099.4609375
Loss(alpha 0.01) for Dopri integrator (one batch): 1500046.375
Loss(alpha 0.01) for Euler integrator (one batch): 1500045.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1500046.375
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8107638888888888
Iter 32 | Test loss (one batch): 32473.345703125
Loss(alpha 0.01) for Dopri integrator (one batch): 600056.0
Loss(alpha 0.01) for Euler integrator (one batch): 600055.3125
Loss(alpha 0.01) for RK4 integrator (one batch): 500056.9375
Choice of integrator (one batch): rk4
Auxiliary network predicted True
AUC of the choice (one batch): 0.9259259259259259
Iter 33 | Test loss (one batch): 51332.1171875
Loss(alpha 0.01) for Dopri integrator (one batch): 2100039.75
Loss(alpha 0.01) for Euler integrator (one batch): 2100039.5
Loss(alpha 0.01) for RK4 integrator (one batch): 2400036.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.5208333333333334
Iter 34 | Test loss (one batch): 27726.853515625
Loss(alpha 0.01) for Dopri integrator (one batch): 300058.96875
Loss(alpha 0.01) for Euler integrator (one batch): 300058.25
Loss(alpha 0.01) for RK4 integrator (one batch): 300059.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.8802083333333333
Iter 35 | Test loss (one batch): 34034.25390625
Loss(alpha 0.01) for Dopri integrator (one batch): 800054.4375
Loss(alpha 0.01) for Euler integrator (one batch): 800052.875
Loss(alpha 0.01) for RK4 integrator (one batch): 900053.375
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.90625
Iter 36 | Test loss (one batch): 48317.9375
Loss(alpha 0.01) for Dopri integrator (one batch): 2000040.75
Loss(alpha 0.01) for Euler integrator (one batch): 2100039.5
Loss(alpha 0.01) for RK4 integrator (one batch): 2100039.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.6971677559912854
Iter 37 | Test loss (one batch): 33778.359375
Loss(alpha 0.01) for Dopri integrator (one batch): 600055.875
Loss(alpha 0.01) for Euler integrator (one batch): 600055.375
Loss(alpha 0.01) for RK4 integrator (one batch): 600056.0
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.6405228758169934
Iter 38 | Test loss (one batch): 37590.05859375
Loss(alpha 0.01) for Dopri integrator (one batch): 1200049.75
Loss(alpha 0.01) for Euler integrator (one batch): 1200048.5
Loss(alpha 0.01) for RK4 integrator (one batch): 1200049.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.6267361111111112
Iter 39 | Test loss (one batch): 50021.4921875
Loss(alpha 0.01) for Dopri integrator (one batch): 1900042.25
Loss(alpha 0.01) for Euler integrator (one batch): 2400036.5
Loss(alpha 0.01) for RK4 integrator (one batch): 2500035.75
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.7134502923976608
Iter 40 | Test loss (one batch): 51536.68359375
Loss(alpha 0.01) for Dopri integrator (one batch): 1800043.25
Loss(alpha 0.01) for Euler integrator (one batch): 2000040.5
Loss(alpha 0.01) for RK4 integrator (one batch): 3200028.5
Choice of integrator (one batch): rk4
Auxiliary network predicted False
AUC of the choice (one batch): 0.6198830409356726
############### TOTAL ###############
Classification AUC : Dopri 0.7616 | Euler 0.7596 | RK4 0.7578
NFE (average): Dopri 38.0 | Euler 10.0 | RK4 40.0
Elapsed time (average): Dopri 0.5633773922920227 | Euler 0.5072531044483185 | RK4 0.5123109459877014
############### Aux Net Average ###############
AUC of the choice 0.7595 | Choice of Dopri5 0 | Euler 0 | RK4 40
Aux Net Runtime: 1601552394.0051
