/home/soyoung/latent_ode0/train_aux.py
train_aux.py --niters 5 -n 8000 -l 20 --latent-ode --z0-encoder rnn --dataset physionet --rec-dims 40 --rec-layers 3 --gen-layers 3 --units 50 --gru-units 50 --quantization 0.016 --classif
### Auxiliary Network : Euler step size 0.1 | RK4 step size 0.0 ###
Iter: 1 | Train loss (one batch): 3.054131507873535
Iter: 2 | Train loss (one batch): 2.9613490104675293
Iter: 3 | Train loss (one batch): 3.023297071456909
Iter: 4 | Train loss (one batch): 2.9579975605010986
Iter: 5 | Train loss (one batch): 2.992766857147217
Iter: 6 | Train loss (one batch): 2.9951956272125244
Iter: 7 | Train loss (one batch): 2.9960122108459473
Iter: 8 | Train loss (one batch): 2.962428331375122
Iter: 9 | Train loss (one batch): 2.8594930171966553
Iter: 10 | Train loss (one batch): 2.839623212814331
Iter: 11 | Train loss (one batch): 2.9430599212646484
Iter: 12 | Train loss (one batch): 2.8951780796051025
Iter: 13 | Train loss (one batch): 2.8375635147094727
Iter: 14 | Train loss (one batch): 2.7943966388702393
Iter: 15 | Train loss (one batch): 2.8111889362335205
Iter: 16 | Train loss (one batch): 2.692852735519409
Iter: 17 | Train loss (one batch): 2.7251365184783936
Iter: 18 | Train loss (one batch): 2.7392992973327637
Iter: 19 | Train loss (one batch): 2.720407485961914
Iter: 20 | Train loss (one batch): 2.7028255462646484
Iter: 21 | Train loss (one batch): 2.6456351280212402
Iter: 22 | Train loss (one batch): 2.5497543811798096
Iter: 23 | Train loss (one batch): 2.572174310684204
Iter: 24 | Train loss (one batch): 2.4710848331451416
Iter: 25 | Train loss (one batch): 2.392387628555298
Iter: 26 | Train loss (one batch): 2.4756767749786377
Iter: 27 | Train loss (one batch): 2.3387796878814697
Iter: 28 | Train loss (one batch): 2.3409552574157715
Iter: 29 | Train loss (one batch): 2.247406244277954
Iter: 30 | Train loss (one batch): 2.2198469638824463
Iter: 31 | Train loss (one batch): 2.154409408569336
Iter: 32 | Train loss (one batch): 2.067279577255249
Iter: 33 | Train loss (one batch): 2.0728416442871094
Iter: 34 | Train loss (one batch): 1.9418885707855225
Iter: 35 | Train loss (one batch): 1.9573304653167725
Iter: 36 | Train loss (one batch): 1.8723794221878052
Iter: 37 | Train loss (one batch): 1.8673824071884155
Iter: 38 | Train loss (one batch): 1.7601503133773804
Iter: 39 | Train loss (one batch): 1.823040246963501
Iter: 40 | Train loss (one batch): 1.7065424919128418
Iter: 41 | Train loss (one batch): 1.6557315587997437
Iter: 42 | Train loss (one batch): 1.6179286241531372
Iter: 43 | Train loss (one batch): 1.563744306564331
Iter: 44 | Train loss (one batch): 1.4898639917373657
Iter: 45 | Train loss (one batch): 1.4422136545181274
Iter: 46 | Train loss (one batch): 1.4004133939743042
Iter: 47 | Train loss (one batch): 1.289597749710083
Iter: 48 | Train loss (one batch): 1.3430461883544922
Iter: 49 | Train loss (one batch): 1.240147590637207
Iter: 50 | Train loss (one batch): 1.2021833658218384
Iter: 51 | Train loss (one batch): 1.2828198671340942
Iter: 52 | Train loss (one batch): 1.1991145610809326
Iter: 53 | Train loss (one batch): 1.2357220649719238
Iter: 54 | Train loss (one batch): 1.1988235712051392
Iter: 55 | Train loss (one batch): 1.1586861610412598
Iter: 56 | Train loss (one batch): 1.1255677938461304
Iter: 57 | Train loss (one batch): 1.0854936838150024
Iter: 58 | Train loss (one batch): 1.0888051986694336
Iter: 59 | Train loss (one batch): 1.153533697128296
Iter: 60 | Train loss (one batch): 1.2068783044815063
Iter: 61 | Train loss (one batch): 1.0728048086166382
Iter: 62 | Train loss (one batch): 1.1116771697998047
Iter: 63 | Train loss (one batch): 1.0248076915740967
Iter: 64 | Train loss (one batch): 1.081523060798645
Iter: 65 | Train loss (one batch): 1.0557880401611328
Iter: 66 | Train loss (one batch): 1.0722458362579346
Iter: 67 | Train loss (one batch): 0.9946471452713013
Iter: 68 | Train loss (one batch): 1.0371843576431274
Iter: 69 | Train loss (one batch): 0.9835851192474365
Iter: 70 | Train loss (one batch): 1.0832637548446655
Iter: 71 | Train loss (one batch): 1.0240628719329834
Iter: 72 | Train loss (one batch): 0.9719359278678894
Iter: 73 | Train loss (one batch): 1.0177204608917236
Iter: 74 | Train loss (one batch): 1.045124888420105
Iter: 75 | Train loss (one batch): 0.9995534420013428
Iter: 76 | Train loss (one batch): 1.0044598579406738
Iter: 77 | Train loss (one batch): 0.9946944117546082
Iter: 78 | Train loss (one batch): 0.9716566205024719
Iter: 79 | Train loss (one batch): 0.9704463481903076
Iter: 80 | Train loss (one batch): 0.8830554485321045
Iter: 81 | Train loss (one batch): 0.8979623913764954
Iter: 82 | Train loss (one batch): 0.8996894955635071
Iter: 83 | Train loss (one batch): 0.9713743329048157
Iter: 84 | Train loss (one batch): 0.9291148781776428
Iter: 85 | Train loss (one batch): 1.0364326238632202
Iter: 86 | Train loss (one batch): 0.9601520895957947
Iter: 87 | Train loss (one batch): 1.0298455953598022
Iter: 88 | Train loss (one batch): 0.9464355111122131
Iter: 89 | Train loss (one batch): 0.9807135462760925
Iter: 90 | Train loss (one batch): 0.9012390971183777
Iter: 91 | Train loss (one batch): 0.9096284508705139
Iter: 92 | Train loss (one batch): 0.9613574147224426
Iter: 93 | Train loss (one batch): 0.8675082921981812
Iter: 94 | Train loss (one batch): 0.9098001718521118
Iter: 95 | Train loss (one batch): 0.9208620190620422
Iter: 96 | Train loss (one batch): 0.876928448677063
Iter: 97 | Train loss (one batch): 0.8889719843864441
Iter: 98 | Train loss (one batch): 0.9259981513023376
Iter: 99 | Train loss (one batch): 0.9620342254638672
Iter: 100 | Train loss (one batch): 0.9512008428573608
Iter: 101 | Train loss (one batch): 0.8838381767272949
Iter: 102 | Train loss (one batch): 0.8294528126716614
Iter: 103 | Train loss (one batch): 0.8394886255264282
Iter: 104 | Train loss (one batch): 0.8703573346138
Iter: 105 | Train loss (one batch): 0.8488453030586243
Iter: 106 | Train loss (one batch): 0.9162304401397705
Iter: 107 | Train loss (one batch): 0.9369271993637085
Iter: 108 | Train loss (one batch): 0.8141674399375916
Iter: 109 | Train loss (one batch): 0.8369765281677246
Iter: 110 | Train loss (one batch): 0.8551429510116577
Iter: 111 | Train loss (one batch): 0.8757429122924805
Iter: 112 | Train loss (one batch): 0.8729535341262817
Iter: 113 | Train loss (one batch): 0.8461438417434692
Iter: 114 | Train loss (one batch): 0.8924630880355835
Iter: 115 | Train loss (one batch): 0.8936777710914612
Iter: 116 | Train loss (one batch): 0.8591179251670837
Iter: 117 | Train loss (one batch): 0.8630433082580566
Iter: 118 | Train loss (one batch): 0.8282181024551392
Iter: 119 | Train loss (one batch): 0.8702494502067566
Iter: 120 | Train loss (one batch): 0.8955301642417908
Iter: 121 | Train loss (one batch): 0.8408762812614441
Iter: 122 | Train loss (one batch): 0.8439714908599854
Iter: 123 | Train loss (one batch): 0.8797582983970642
Iter: 124 | Train loss (one batch): 0.8747634291648865
Iter: 125 | Train loss (one batch): 0.8962846398353577
Iter: 126 | Train loss (one batch): 0.8435596823692322
Iter: 127 | Train loss (one batch): 0.9225821495056152
Iter: 128 | Train loss (one batch): 0.8903326988220215
Iter: 129 | Train loss (one batch): 0.8251947164535522
Iter: 130 | Train loss (one batch): 0.8861257433891296
Iter: 131 | Train loss (one batch): 0.8319882750511169
Iter: 132 | Train loss (one batch): 0.811543345451355
Iter: 133 | Train loss (one batch): 0.8421728014945984
Iter: 134 | Train loss (one batch): 0.8054659366607666
Iter: 135 | Train loss (one batch): 0.8564744591712952
Iter: 136 | Train loss (one batch): 0.8574041724205017
Iter: 137 | Train loss (one batch): 0.8941828608512878
Iter: 138 | Train loss (one batch): 0.8605202436447144
Iter: 139 | Train loss (one batch): 0.8422148823738098
Iter: 140 | Train loss (one batch): 0.8564746379852295
Iter: 141 | Train loss (one batch): 0.7991849184036255
Iter: 142 | Train loss (one batch): 0.8420372009277344
Iter: 143 | Train loss (one batch): 0.8127628564834595
Iter: 144 | Train loss (one batch): 0.8943269848823547
Iter: 145 | Train loss (one batch): 0.7339244484901428
Iter: 146 | Train loss (one batch): 0.7543739676475525
Iter: 147 | Train loss (one batch): 0.748384416103363
Iter: 148 | Train loss (one batch): 0.7679410576820374
Iter: 149 | Train loss (one batch): 0.8646432757377625
Iter: 150 | Train loss (one batch): 0.8244816064834595
Iter: 151 | Train loss (one batch): 0.7671527862548828
Iter: 152 | Train loss (one batch): 0.8252177834510803
Iter: 153 | Train loss (one batch): 0.8859483599662781
Iter: 154 | Train loss (one batch): 0.7660465836524963
Iter: 155 | Train loss (one batch): 0.8632628917694092
Iter: 156 | Train loss (one batch): 0.8432591557502747
Iter: 157 | Train loss (one batch): 0.7448970675468445
Iter: 158 | Train loss (one batch): 0.7431920766830444
Iter: 159 | Train loss (one batch): 0.7808830738067627
Iter: 160 | Train loss (one batch): 0.8488397598266602
Iter: 161 | Train loss (one batch): 0.8177664875984192
Iter: 162 | Train loss (one batch): 0.8016802668571472
Iter: 163 | Train loss (one batch): 0.7843846678733826
Iter: 164 | Train loss (one batch): 0.8370828032493591
Iter: 165 | Train loss (one batch): 0.7937557101249695
Iter: 166 | Train loss (one batch): 0.7864308953285217
Iter: 167 | Train loss (one batch): 0.7390828132629395
Iter: 168 | Train loss (one batch): 0.7438259720802307
Iter: 169 | Train loss (one batch): 0.7866650819778442
Iter: 170 | Train loss (one batch): 0.8013725876808167
Iter: 171 | Train loss (one batch): 0.7552136778831482
Iter: 172 | Train loss (one batch): 0.8217411637306213
Iter: 173 | Train loss (one batch): 0.7866201996803284
Iter: 174 | Train loss (one batch): 0.8564852476119995
Iter: 175 | Train loss (one batch): 0.7829478979110718
Iter: 176 | Train loss (one batch): 0.712765097618103
Iter: 177 | Train loss (one batch): 0.7410419583320618
Iter: 178 | Train loss (one batch): 0.8179829716682434
Iter: 179 | Train loss (one batch): 0.7739112973213196
Iter: 180 | Train loss (one batch): 0.7835273146629333
Iter: 181 | Train loss (one batch): 0.788780927658081
Iter: 182 | Train loss (one batch): 0.7484869956970215
Iter: 183 | Train loss (one batch): 0.8095576167106628
Iter: 184 | Train loss (one batch): 0.7476407885551453
Iter: 185 | Train loss (one batch): 0.8124087452888489
Iter: 186 | Train loss (one batch): 0.7207317352294922
Iter: 187 | Train loss (one batch): 0.7363231778144836
Iter: 188 | Train loss (one batch): 0.834783673286438
Iter: 189 | Train loss (one batch): 0.7525674700737
Iter: 190 | Train loss (one batch): 0.772973358631134
Iter: 191 | Train loss (one batch): 0.6927627325057983
Iter: 192 | Train loss (one batch): 0.742758572101593
Iter: 193 | Train loss (one batch): 0.7575758695602417
Iter: 194 | Train loss (one batch): 0.8023983240127563
Iter: 195 | Train loss (one batch): 0.765326201915741
Iter: 196 | Train loss (one batch): 0.8281779289245605
Iter: 197 | Train loss (one batch): 0.8193929195404053
Iter: 198 | Train loss (one batch): 0.750857412815094
Iter: 199 | Train loss (one batch): 0.7689265608787537
Iter: 200 | Train loss (one batch): 0.7750498056411743
Iter: 201 | Train loss (one batch): 0.7618860602378845
Iter: 202 | Train loss (one batch): 0.806612491607666
Iter: 203 | Train loss (one batch): 0.7395917177200317
Iter: 204 | Train loss (one batch): 0.7592506408691406
Iter: 205 | Train loss (one batch): 0.6904836297035217
Iter: 206 | Train loss (one batch): 0.7271554470062256
Iter: 207 | Train loss (one batch): 0.7548001408576965
Iter: 208 | Train loss (one batch): 0.6942739486694336
Iter: 209 | Train loss (one batch): 0.8901574015617371
Iter: 210 | Train loss (one batch): 0.7616668939590454
Iter: 211 | Train loss (one batch): 0.763327956199646
Iter: 212 | Train loss (one batch): 0.7797353267669678
Iter: 213 | Train loss (one batch): 0.7708642482757568
Iter: 214 | Train loss (one batch): 0.7520304918289185
Iter: 215 | Train loss (one batch): 0.7264500260353088
Iter: 216 | Train loss (one batch): 0.8072696924209595
Iter: 217 | Train loss (one batch): 0.7893263697624207
Iter: 218 | Train loss (one batch): 0.7608873248100281
Iter: 219 | Train loss (one batch): 0.7610249519348145
Iter: 220 | Train loss (one batch): 0.700006365776062
Iter: 221 | Train loss (one batch): 0.6252620816230774
Iter: 222 | Train loss (one batch): 0.8203563690185547
Iter: 223 | Train loss (one batch): 0.7511013746261597
Iter: 224 | Train loss (one batch): 0.7643800973892212
Iter: 225 | Train loss (one batch): 0.7418859601020813
Iter: 226 | Train loss (one batch): 0.850459098815918
Iter: 227 | Train loss (one batch): 0.757389485836029
Iter: 228 | Train loss (one batch): 0.8100293278694153
Iter: 229 | Train loss (one batch): 0.7604040503501892
Iter: 230 | Train loss (one batch): 0.7426554560661316
Iter: 231 | Train loss (one batch): 0.7311995029449463
Iter: 232 | Train loss (one batch): 0.7356765866279602
Iter: 233 | Train loss (one batch): 0.7018113732337952
Iter: 234 | Train loss (one batch): 0.7597991824150085
Iter: 235 | Train loss (one batch): 0.7551565766334534
Iter: 236 | Train loss (one batch): 0.7003456950187683
Iter: 237 | Train loss (one batch): 0.7537940144538879
Iter: 238 | Train loss (one batch): 0.6915812492370605
Iter: 239 | Train loss (one batch): 0.7412418723106384
Iter: 240 | Train loss (one batch): 0.7396469116210938
Iter: 241 | Train loss (one batch): 0.7352486252784729
Iter: 242 | Train loss (one batch): 0.7133183479309082
Iter: 243 | Train loss (one batch): 0.7476145029067993
Iter: 244 | Train loss (one batch): 0.7208544611930847
Iter: 245 | Train loss (one batch): 0.7557283639907837
Iter: 246 | Train loss (one batch): 0.7346703410148621
Iter: 247 | Train loss (one batch): 0.7787995934486389
Iter: 248 | Train loss (one batch): 0.7639829516410828
Iter: 249 | Train loss (one batch): 0.6837882995605469
Iter: 250 | Train loss (one batch): 0.7111230492591858
Iter: 251 | Train loss (one batch): 0.6923556923866272
Iter: 252 | Train loss (one batch): 0.7562337517738342
Iter: 253 | Train loss (one batch): 0.7087551355361938
Iter: 254 | Train loss (one batch): 0.7323091626167297
Iter: 255 | Train loss (one batch): 0.7191159725189209
Iter: 256 | Train loss (one batch): 0.7381426095962524
Iter: 257 | Train loss (one batch): 0.7321920990943909
Iter: 258 | Train loss (one batch): 0.7135440111160278
Iter: 259 | Train loss (one batch): 0.6789376735687256
Iter: 260 | Train loss (one batch): 0.7546674013137817
Iter: 261 | Train loss (one batch): 0.7304875254631042
Iter: 262 | Train loss (one batch): 0.7265570163726807
Iter: 263 | Train loss (one batch): 0.700735330581665
Iter: 264 | Train loss (one batch): 0.7061015367507935
Iter: 265 | Train loss (one batch): 0.6827845573425293
Iter: 266 | Train loss (one batch): 0.7201780676841736
Iter: 267 | Train loss (one batch): 0.6440929770469666
Iter: 268 | Train loss (one batch): 0.7131233811378479
Iter: 269 | Train loss (one batch): 0.7547887563705444
Iter: 270 | Train loss (one batch): 0.8155003786087036
Iter: 271 | Train loss (one batch): 0.7276290655136108
Iter: 272 | Train loss (one batch): 0.6848164200782776
Iter: 273 | Train loss (one batch): 0.7183263897895813
Iter: 274 | Train loss (one batch): 0.7341164350509644
Iter: 275 | Train loss (one batch): 0.7150757908821106
Iter: 276 | Train loss (one batch): 0.6480638384819031
Iter: 277 | Train loss (one batch): 0.658968448638916
Iter: 278 | Train loss (one batch): 0.7317066788673401
Iter: 279 | Train loss (one batch): 0.6707851886749268
Iter: 280 | Train loss (one batch): 0.7017470002174377
Iter: 281 | Train loss (one batch): 0.7454513907432556
Iter: 282 | Train loss (one batch): 0.659000813961029
Iter: 283 | Train loss (one batch): 0.6971597075462341
Iter: 284 | Train loss (one batch): 0.6801754832267761
Iter: 285 | Train loss (one batch): 0.5851949453353882
Iter: 286 | Train loss (one batch): 0.7996050715446472
Iter: 287 | Train loss (one batch): 0.6720451712608337
Iter: 288 | Train loss (one batch): 0.6835607290267944
Iter: 289 | Train loss (one batch): 0.6570322513580322
Iter: 290 | Train loss (one batch): 0.7741200923919678
Iter: 291 | Train loss (one batch): 0.6683998703956604
Iter: 292 | Train loss (one batch): 0.7344018816947937
Iter: 293 | Train loss (one batch): 0.6583666205406189
Iter: 294 | Train loss (one batch): 0.6446662545204163
Iter: 295 | Train loss (one batch): 0.6758570075035095
Iter: 296 | Train loss (one batch): 0.6941629648208618
Iter: 297 | Train loss (one batch): 0.6375398635864258
Iter: 298 | Train loss (one batch): 0.7087648510932922
Iter: 299 | Train loss (one batch): 0.5939376354217529
Iter: 300 | Train loss (one batch): 0.6973270773887634
Iter: 301 | Train loss (one batch): 0.701793909072876
Iter: 302 | Train loss (one batch): 0.7277569770812988
Iter: 303 | Train loss (one batch): 0.6880380511283875
Iter: 304 | Train loss (one batch): 0.694727897644043
Iter: 305 | Train loss (one batch): 0.713691771030426
Iter: 306 | Train loss (one batch): 0.648248553276062
Iter: 307 | Train loss (one batch): 0.7239563465118408
Iter: 308 | Train loss (one batch): 0.7019997239112854
Iter: 309 | Train loss (one batch): 0.6771661639213562
Iter: 310 | Train loss (one batch): 0.684891939163208
Iter: 311 | Train loss (one batch): 0.7255975604057312
Iter: 312 | Train loss (one batch): 0.6841380596160889
Iter: 313 | Train loss (one batch): 0.622433602809906
Iter: 314 | Train loss (one batch): 0.6841462254524231
Iter: 315 | Train loss (one batch): 0.6760280728340149
Iter: 316 | Train loss (one batch): 0.7391588091850281
Iter: 317 | Train loss (one batch): 0.6903421878814697
Iter: 318 | Train loss (one batch): 0.6552200317382812
Iter: 319 | Train loss (one batch): 0.6431702971458435
Iter: 320 | Train loss (one batch): 0.661554217338562
Iter: 321 | Train loss (one batch): 0.6795377135276794
Iter: 322 | Train loss (one batch): 0.7398259043693542
Iter: 323 | Train loss (one batch): 0.6476049423217773
Iter: 324 | Train loss (one batch): 0.6713327765464783
Iter: 325 | Train loss (one batch): 0.6942339539527893
Iter: 326 | Train loss (one batch): 0.6977481842041016
Iter: 327 | Train loss (one batch): 0.6619288325309753
Iter: 328 | Train loss (one batch): 0.6368284821510315
Iter: 329 | Train loss (one batch): 0.682876467704773
Iter: 330 | Train loss (one batch): 0.734538733959198
Iter: 331 | Train loss (one batch): 0.627699077129364
Iter: 332 | Train loss (one batch): 0.6364448070526123
Iter: 333 | Train loss (one batch): 0.6284172534942627
Iter: 334 | Train loss (one batch): 0.7196700572967529
Iter: 335 | Train loss (one batch): 0.6991565227508545
Iter: 336 | Train loss (one batch): 0.759367048740387
Iter: 337 | Train loss (one batch): 0.6945943236351013
Iter: 338 | Train loss (one batch): 0.735602617263794
Iter: 339 | Train loss (one batch): 0.7245111465454102
Iter: 340 | Train loss (one batch): 0.6603022813796997
Iter: 341 | Train loss (one batch): 0.6079962253570557
Iter: 342 | Train loss (one batch): 0.6563555002212524
Iter: 343 | Train loss (one batch): 0.6082078814506531
Iter: 344 | Train loss (one batch): 0.7094766497612
Iter: 345 | Train loss (one batch): 0.7266525626182556
Iter: 346 | Train loss (one batch): 0.6619335412979126
Iter: 347 | Train loss (one batch): 0.6538376808166504
Iter: 348 | Train loss (one batch): 0.6424392461776733
Iter: 349 | Train loss (one batch): 0.624855637550354
Iter: 350 | Train loss (one batch): 0.6947428584098816
Iter: 351 | Train loss (one batch): 0.6482304334640503
Iter: 352 | Train loss (one batch): 0.6700218915939331
Iter: 353 | Train loss (one batch): 0.6205962300300598
Iter: 354 | Train loss (one batch): 0.7366824746131897
Iter: 355 | Train loss (one batch): 0.6941107511520386
Iter: 356 | Train loss (one batch): 0.6876664757728577
Iter: 357 | Train loss (one batch): 0.6633016467094421
Iter: 358 | Train loss (one batch): 0.6346473693847656
Iter: 359 | Train loss (one batch): 0.6166092157363892
Iter: 360 | Train loss (one batch): 0.6415941119194031
Iter: 361 | Train loss (one batch): 0.6347306966781616
Iter: 362 | Train loss (one batch): 0.6612470149993896
Iter: 363 | Train loss (one batch): 0.6745483875274658
Iter: 364 | Train loss (one batch): 0.6035746335983276
Iter: 365 | Train loss (one batch): 0.6292170882225037
Iter: 366 | Train loss (one batch): 0.6648480296134949
Iter: 367 | Train loss (one batch): 0.6099233031272888
Iter: 368 | Train loss (one batch): 0.617933452129364
Iter: 369 | Train loss (one batch): 0.6390162706375122
Iter: 370 | Train loss (one batch): 0.7252819538116455
Iter: 371 | Train loss (one batch): 0.5931344032287598
Iter: 372 | Train loss (one batch): 0.6403050422668457
Iter: 373 | Train loss (one batch): 0.5964263081550598
Iter: 374 | Train loss (one batch): 0.6575297117233276
Iter: 375 | Train loss (one batch): 0.6820902228355408
Iter: 376 | Train loss (one batch): 0.7105557322502136
Iter: 377 | Train loss (one batch): 0.6483392715454102
Iter: 378 | Train loss (one batch): 0.6360983848571777
Iter: 379 | Train loss (one batch): 0.6722748875617981
Iter: 380 | Train loss (one batch): 0.7145391702651978
Iter: 381 | Train loss (one batch): 0.6295941472053528
Iter: 382 | Train loss (one batch): 0.6762332916259766
Iter: 383 | Train loss (one batch): 0.6474046111106873
Experiment 59645
### Auxiliary Network : n_test_batches 40 ###
Iter 1 | Test loss (one batch): 0.4268419146537781
Loss(alpha 0.3) for Dopri integrator (one batch): 194.1566162109375
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.1072235107422
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.7821350762527232
Iter 2 | Test loss (one batch): 0.317155659198761
Loss(alpha 0.3) for Dopri integrator (one batch): 212.76678466796875
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 181.45504760742188
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.0
Iter 3 | Test loss (one batch): 0.3787059187889099
Loss(alpha 0.3) for Dopri integrator (one batch): 223.39761352539062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 181.45504760742188
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.0
Iter 4 | Test loss (one batch): 0.42052507400512695
Loss(alpha 0.3) for Dopri integrator (one batch): 203.4556427001953
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 172.1941680908203
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8641975308641975
Iter 5 | Test loss (one batch): 0.39307311177253723
Loss(alpha 0.3) for Dopri integrator (one batch): 203.46170043945312
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.5709876543209876
Iter 6 | Test loss (one batch): 0.4574064612388611
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52976989746094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.10720825195312
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.7986111111111112
Iter 7 | Test loss (one batch): 0.4533531963825226
Loss(alpha 0.3) for Dopri integrator (one batch): 191.05491638183594
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 166.02027893066406
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.6041666666666667
Iter 8 | Test loss (one batch): 0.4742971956729889
Loss(alpha 0.3) for Dopri integrator (one batch): 193.60389709472656
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 166.020263671875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.873015873015873
Iter 9 | Test loss (one batch): 0.38371741771698
Loss(alpha 0.3) for Dopri integrator (one batch): 197.25830078125
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 170.13619995117188
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9409722222222222
Iter 10 | Test loss (one batch): 0.3879527151584625
Loss(alpha 0.3) for Dopri integrator (one batch): 208.3815155029297
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9506172839506173
Iter 11 | Test loss (one batch): 0.4465726613998413
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52976989746094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.1072235107422
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.7211328976034859
Iter 12 | Test loss (one batch): 0.41953930258750916
Loss(alpha 0.3) for Dopri integrator (one batch): 208.38150024414062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9907407407407408
Iter 13 | Test loss (one batch): 0.3710295259952545
Loss(alpha 0.3) for Dopri integrator (one batch): 213.307373046875
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.3680877685547
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9005847953216375
Iter 14 | Test loss (one batch): 0.41479936242103577
Loss(alpha 0.3) for Dopri integrator (one batch): 213.307373046875
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.36807250976562
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.3508771929824562
Iter 15 | Test loss (one batch): 0.4937101900577545
Loss(alpha 0.3) for Dopri integrator (one batch): 193.60389709472656
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 166.02024841308594
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.5792592592592593
Iter 16 | Test loss (one batch): 0.36541086435317993
Loss(alpha 0.3) for Dopri integrator (one batch): 213.307373046875
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.3680877685547
Choice of integrator (one batch): euler
AUC of the choice (one batch): 1.0
Iter 17 | Test loss (one batch): 0.3913673162460327
Loss(alpha 0.3) for Dopri integrator (one batch): 190.95831298828125
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 171.16519165039062
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.845486111111111
Iter 18 | Test loss (one batch): 0.44587528705596924
Loss(alpha 0.3) for Dopri integrator (one batch): 203.4556427001953
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 172.19418334960938
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.49673202614379086
Iter 19 | Test loss (one batch): 0.43280792236328125
Loss(alpha 0.3) for Dopri integrator (one batch): 208.38150024414062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.15432098765432098
Iter 20 | Test loss (one batch): 0.33502304553985596
Loss(alpha 0.3) for Dopri integrator (one batch): 208.11424255371094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.3680877685547
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9824561403508771
Iter 21 | Test loss (one batch): 0.3663298785686493
Loss(alpha 0.3) for Dopri integrator (one batch): 213.307373046875
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.36807250976562
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9122807017543859
Iter 22 | Test loss (one batch): 0.35826221108436584
Loss(alpha 0.3) for Dopri integrator (one batch): 214.94932556152344
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.3680877685547
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.0
Iter 23 | Test loss (one batch): 0.41918277740478516
Loss(alpha 0.3) for Dopri integrator (one batch): 208.38150024414062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.5277777777777778
Iter 24 | Test loss (one batch): 0.40613114833831787
Loss(alpha 0.3) for Dopri integrator (one batch): 208.38150024414062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.28114318847656
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8518518518518519
Iter 25 | Test loss (one batch): 0.48042401671409607
Loss(alpha 0.3) for Dopri integrator (one batch): 193.60389709472656
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 164.9912872314453
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.6597222222222222
Iter 26 | Test loss (one batch): 0.396491676568985
Loss(alpha 0.3) for Dopri integrator (one batch): 208.38150024414062
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9166666666666667
Iter 27 | Test loss (one batch): 0.4487367868423462
Loss(alpha 0.3) for Dopri integrator (one batch): 203.4556427001953
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 172.19418334960938
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8758169934640523
Iter 28 | Test loss (one batch): 0.37831905484199524
Loss(alpha 0.3) for Dopri integrator (one batch): 211.6654052734375
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 178.3680877685547
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9473684210526316
Iter 29 | Test loss (one batch): 0.4242101013660431
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52978515625
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.1072235107422
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8940972222222222
Iter 30 | Test loss (one batch): 0.42934221029281616
Loss(alpha 0.3) for Dopri integrator (one batch): 203.45562744140625
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 172.1941680908203
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.9128540305010894
Iter 31 | Test loss (one batch): 0.4671000838279724
Loss(alpha 0.3) for Dopri integrator (one batch): 189.50404357910156
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 166.020263671875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.7881944444444444
Iter 32 | Test loss (one batch): 0.48509398102760315
Loss(alpha 0.3) for Dopri integrator (one batch): 188.67803955078125
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 162.93331909179688
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8690476190476191
Iter 33 | Test loss (one batch): 0.4719851016998291
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52976989746094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.1072235107422
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.5815972222222222
Iter 34 | Test loss (one batch): 0.45271751284599304
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52976989746094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.10720825195312
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8854166666666667
Iter 35 | Test loss (one batch): 0.41973772644996643
Loss(alpha 0.3) for Dopri integrator (one batch): 194.1566162109375
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.10720825195312
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.8975694444444444
Iter 36 | Test loss (one batch): 0.47153669595718384
Loss(alpha 0.3) for Dopri integrator (one batch): 193.60391235351562
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 166.02027893066406
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.6296296296296297
Iter 37 | Test loss (one batch): 0.416716068983078
Loss(alpha 0.3) for Dopri integrator (one batch): 200.36000061035156
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 172.1941680908203
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.6100217864923747
Iter 38 | Test loss (one batch): 0.44058144092559814
Loss(alpha 0.3) for Dopri integrator (one batch): 198.52976989746094
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 169.10720825195312
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.7152777777777778
Iter 39 | Test loss (one batch): 0.35345664620399475
Loss(alpha 0.3) for Dopri integrator (one batch): 206.56338500976562
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 177.339111328125
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.783625730994152
Iter 40 | Test loss (one batch): 0.4078819453716278
Loss(alpha 0.3) for Dopri integrator (one batch): 208.3815155029297
Loss(alpha 0.3) for Euler integrator (one batch): 119.71573638916016
Loss(alpha 0.3) for RK4 integrator (one batch): 175.2811279296875
Choice of integrator (one batch): euler
AUC of the choice (one batch): 0.1228070175438597
############### TOTAL ###############
Classification AUC : Dopri 0.7499 | Euler 0.7485 | RK4 0.7501
NFE (average): Dopri 72.05 | Euler 10.0 | RK4 40.0
Elapsed time (average): Dopri 0.3224265933036804 | Euler 0.13242344856262206 | RK4 0.13988420367240906
############### Aux Net Average ###############
Avg AUC 0.1228 | Choice of Dopri5 0 | Euler 40 | RK4 0
Aux Net Runtime: 1601515495.7493
